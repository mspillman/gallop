<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>gallop.multiGPU API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gallop.multiGPU</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch
import multiprocessing as mp
import numpy as np
import time
from gallop import structure
from gallop import optimiser
from gallop import files

def multiGPU(GPU, start, end, external, internal, structure_files,
            minimiser_settings):
    &#34;&#34;&#34;
    Process GALLLOP jobs on multiple GPUs

    Args:
        GPU (int): The GPU to use. Typically, this will be zero-indexed, so in
            total, would expect inputs from 0 to (NGPUs - 1). This assigns the
            GPU to the particular process.
        start (int): The particle index start - defines which section of the
            external and internal arrays to read from
        end (int): The particle index end - defines which section of the
            external and internal arrays to read from
        external (np.array): External degrees of freedom for ALL particles, not
            just those assigned to this GPU
        internal (np.array): Internal degrees of freedom for ALL particles, not
            just those assigned to this GPU
        structure_files (dict): The filenames and some structure settings needed
            to generate a temporary structure object. This is needed as it&#39;s not
            possible to pickle the structure object directly.
        minimiser_settings (dict): Settings needed for the local optimisation

    Returns:
        dict: standard gallop results dictionary, as the value of a dict with
            the GPU value as the key. This is used to reconstruct the full
            results needed for the particle swarm update step.
    &#34;&#34;&#34;
    minimiser_settings[&#34;device&#34;] = torch.device(&#34;cuda:&#34;+str(GPU))
    external = external[start:end]
    internal = internal[start:end]
    temp_struct = structure.Structure()
    temp_struct.from_json(structure_files, is_json=False)
    result = optimiser.minimise(temp_struct, external=external, internal=internal,
                                **minimiser_settings)
    result = {GPU : result}
    return result


def minimise(i, struct, swarm, external, internal, GPU_split,
            minimiser_settings, start_time=None):
    &#34;&#34;&#34;[summary]

    Args:
        i (int): [description]
        struct (gallop.Structure): [description]
        swarm (gallop.Swarm): [description]
        external (np.array): [description]
        internal (np.array): [description]
        GPU_split (List of lists): List of lists with the following structure:
                    [[GPU_1, % on GPU_1],
                    [GPU_2, % on GPU_2],
                                ... ...
                    [GPU_N, % on GPU_N]]
            The GPU IDs are integers that correspond to the index obtained using
            torch.cuda.device_count() and torch.cuda.get_device_name(i) where
            i is produced by range(torch.cuda.device_count()). The percentage is
            expressed in the range [0,100] rather than [0,1].
        minimiser_settings (dict): Dictionary with the settings needed for the
            local optimiser
        start_time (float, optional): The time at which the runs started. Used
            in the save_CIF function to add timestamps to the files.
            Defaults to None.

    Returns:
        dict: Standard gallop results dictionary as would normally be obtained
        using the optimiser.minimise function
    &#34;&#34;&#34;
    structure_files = struct.to_json(return_json=False)
    minimiser_settings[&#34;streamlit&#34;] = False
    minimiser_settings[&#34;save_CIF&#34;] = False
    common_args = [external, internal, structure_files, minimiser_settings]
    args = []
    devices = []
    for i, g in enumerate(GPU_split):
        gpuid = int(g[0])
        devices.append(gpuid)
        percentage = g[1] / 100.
        if i == 0:
            start = 0
            end = int(np.ceil(percentage*swarm.n_particles))
        else:
            start = end
            end = start + int(np.ceil(percentage*swarm.n_particles))
        args.append([gpuid,start,end]+common_args)
    if start_time is None:
        start_time = time.time()
    with mp.Pool(processes = len(GPU_split)) as p:
        results = p.starmap(multiGPU, args)
    p.close()
    p.join()
    combined = results[0]
    for x in results[1:]:
        combined.update(x)
    # Now reconstruct the full results dict
    result = {&#34;GALLOP Iter&#34; : i}
    for d in devices:
        if &#34;external&#34; in result.keys():
            result[&#34;external&#34;] = np.vstack([result[&#34;external&#34;],
                                            combined[d][&#34;external&#34;]])
        else:
            result[&#34;external&#34;] = combined[d][&#34;external&#34;]
        if &#34;internal&#34; in result.keys():
            result[&#34;internal&#34;] = np.vstack([result[&#34;internal&#34;],
                                            combined[d][&#34;internal&#34;]])
        else:
            result[&#34;internal&#34;] = combined[d][&#34;internal&#34;]
        if &#34;chi_2&#34; in result.keys():
            result[&#34;chi_2&#34;] = np.hstack([result[&#34;chi_2&#34;], combined[d][&#34;chi_2&#34;]])
        else:
            result[&#34;chi_2&#34;] = combined[d][&#34;chi_2&#34;]
    files.save_CIF_of_best_result(struct, result, start_time,
                                    minimiser_settings[&#34;n_reflections&#34;])
    return result</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="gallop.multiGPU.minimise"><code class="name flex">
<span>def <span class="ident">minimise</span></span>(<span>i, struct, swarm, external, internal, GPU_split, minimiser_settings, start_time=None)</span>
</code></dt>
<dd>
<div class="desc"><p>[summary]</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>i</code></strong> :&ensp;<code>int</code></dt>
<dd>[description]</dd>
<dt><strong><code>struct</code></strong> :&ensp;<code>gallop.Structure</code></dt>
<dd>[description]</dd>
<dt><strong><code>swarm</code></strong> :&ensp;<code>gallop.Swarm</code></dt>
<dd>[description]</dd>
<dt><strong><code>external</code></strong> :&ensp;<code>np.array</code></dt>
<dd>[description]</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>np.array</code></dt>
<dd>[description]</dd>
<dt><strong><code>GPU_split</code></strong> :&ensp;<code>List</code> of <code>lists</code></dt>
<dd>List of lists with the following structure:
[[GPU_1, % on GPU_1],
[GPU_2, % on GPU_2],
&hellip; &hellip;
[GPU_N, % on GPU_N]]
The GPU IDs are integers that correspond to the index obtained using
torch.cuda.device_count() and torch.cuda.get_device_name(i) where
i is produced by range(torch.cuda.device_count()). The percentage is
expressed in the range [0,100] rather than [0,1].</dd>
<dt><strong><code>minimiser_settings</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary with the settings needed for the
local optimiser</dd>
<dt><strong><code>start_time</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The time at which the runs started. Used
in the save_CIF function to add timestamps to the files.
Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Standard gallop results dictionary as would normally be obtained</dd>
</dl>
<p>using the optimiser.minimise function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def minimise(i, struct, swarm, external, internal, GPU_split,
            minimiser_settings, start_time=None):
    &#34;&#34;&#34;[summary]

    Args:
        i (int): [description]
        struct (gallop.Structure): [description]
        swarm (gallop.Swarm): [description]
        external (np.array): [description]
        internal (np.array): [description]
        GPU_split (List of lists): List of lists with the following structure:
                    [[GPU_1, % on GPU_1],
                    [GPU_2, % on GPU_2],
                                ... ...
                    [GPU_N, % on GPU_N]]
            The GPU IDs are integers that correspond to the index obtained using
            torch.cuda.device_count() and torch.cuda.get_device_name(i) where
            i is produced by range(torch.cuda.device_count()). The percentage is
            expressed in the range [0,100] rather than [0,1].
        minimiser_settings (dict): Dictionary with the settings needed for the
            local optimiser
        start_time (float, optional): The time at which the runs started. Used
            in the save_CIF function to add timestamps to the files.
            Defaults to None.

    Returns:
        dict: Standard gallop results dictionary as would normally be obtained
        using the optimiser.minimise function
    &#34;&#34;&#34;
    structure_files = struct.to_json(return_json=False)
    minimiser_settings[&#34;streamlit&#34;] = False
    minimiser_settings[&#34;save_CIF&#34;] = False
    common_args = [external, internal, structure_files, minimiser_settings]
    args = []
    devices = []
    for i, g in enumerate(GPU_split):
        gpuid = int(g[0])
        devices.append(gpuid)
        percentage = g[1] / 100.
        if i == 0:
            start = 0
            end = int(np.ceil(percentage*swarm.n_particles))
        else:
            start = end
            end = start + int(np.ceil(percentage*swarm.n_particles))
        args.append([gpuid,start,end]+common_args)
    if start_time is None:
        start_time = time.time()
    with mp.Pool(processes = len(GPU_split)) as p:
        results = p.starmap(multiGPU, args)
    p.close()
    p.join()
    combined = results[0]
    for x in results[1:]:
        combined.update(x)
    # Now reconstruct the full results dict
    result = {&#34;GALLOP Iter&#34; : i}
    for d in devices:
        if &#34;external&#34; in result.keys():
            result[&#34;external&#34;] = np.vstack([result[&#34;external&#34;],
                                            combined[d][&#34;external&#34;]])
        else:
            result[&#34;external&#34;] = combined[d][&#34;external&#34;]
        if &#34;internal&#34; in result.keys():
            result[&#34;internal&#34;] = np.vstack([result[&#34;internal&#34;],
                                            combined[d][&#34;internal&#34;]])
        else:
            result[&#34;internal&#34;] = combined[d][&#34;internal&#34;]
        if &#34;chi_2&#34; in result.keys():
            result[&#34;chi_2&#34;] = np.hstack([result[&#34;chi_2&#34;], combined[d][&#34;chi_2&#34;]])
        else:
            result[&#34;chi_2&#34;] = combined[d][&#34;chi_2&#34;]
    files.save_CIF_of_best_result(struct, result, start_time,
                                    minimiser_settings[&#34;n_reflections&#34;])
    return result</code></pre>
</details>
</dd>
<dt id="gallop.multiGPU.multiGPU"><code class="name flex">
<span>def <span class="ident">multiGPU</span></span>(<span>GPU, start, end, external, internal, structure_files, minimiser_settings)</span>
</code></dt>
<dd>
<div class="desc"><p>Process GALLLOP jobs on multiple GPUs</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>GPU</code></strong> :&ensp;<code>int</code></dt>
<dd>The GPU to use. Typically, this will be zero-indexed, so in
total, would expect inputs from 0 to (NGPUs - 1). This assigns the
GPU to the particular process.</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>int</code></dt>
<dd>The particle index start - defines which section of the
external and internal arrays to read from</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>int</code></dt>
<dd>The particle index end - defines which section of the
external and internal arrays to read from</dd>
<dt><strong><code>external</code></strong> :&ensp;<code>np.array</code></dt>
<dd>External degrees of freedom for ALL particles, not
just those assigned to this GPU</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>np.array</code></dt>
<dd>Internal degrees of freedom for ALL particles, not
just those assigned to this GPU</dd>
<dt><strong><code>structure_files</code></strong> :&ensp;<code>dict</code></dt>
<dd>The filenames and some structure settings needed
to generate a temporary structure object. This is needed as it's not
possible to pickle the structure object directly.</dd>
<dt><strong><code>minimiser_settings</code></strong> :&ensp;<code>dict</code></dt>
<dd>Settings needed for the local optimisation</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>standard gallop results dictionary, as the value of a dict with
the GPU value as the key. This is used to reconstruct the full
results needed for the particle swarm update step.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def multiGPU(GPU, start, end, external, internal, structure_files,
            minimiser_settings):
    &#34;&#34;&#34;
    Process GALLLOP jobs on multiple GPUs

    Args:
        GPU (int): The GPU to use. Typically, this will be zero-indexed, so in
            total, would expect inputs from 0 to (NGPUs - 1). This assigns the
            GPU to the particular process.
        start (int): The particle index start - defines which section of the
            external and internal arrays to read from
        end (int): The particle index end - defines which section of the
            external and internal arrays to read from
        external (np.array): External degrees of freedom for ALL particles, not
            just those assigned to this GPU
        internal (np.array): Internal degrees of freedom for ALL particles, not
            just those assigned to this GPU
        structure_files (dict): The filenames and some structure settings needed
            to generate a temporary structure object. This is needed as it&#39;s not
            possible to pickle the structure object directly.
        minimiser_settings (dict): Settings needed for the local optimisation

    Returns:
        dict: standard gallop results dictionary, as the value of a dict with
            the GPU value as the key. This is used to reconstruct the full
            results needed for the particle swarm update step.
    &#34;&#34;&#34;
    minimiser_settings[&#34;device&#34;] = torch.device(&#34;cuda:&#34;+str(GPU))
    external = external[start:end]
    internal = internal[start:end]
    temp_struct = structure.Structure()
    temp_struct.from_json(structure_files, is_json=False)
    result = optimiser.minimise(temp_struct, external=external, internal=internal,
                                **minimiser_settings)
    result = {GPU : result}
    return result</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gallop" href="index.html">gallop</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="gallop.multiGPU.minimise" href="#gallop.multiGPU.minimise">minimise</a></code></li>
<li><code><a title="gallop.multiGPU.multiGPU" href="#gallop.multiGPU.multiGPU">multiGPU</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>