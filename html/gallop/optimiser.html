<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>gallop.optimiser API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gallop.optimiser</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import time
import os
import random
import torch
import tqdm
import pyDOE
import numpy as np
import matplotlib.pyplot as plt
import torch_optimizer as t_optim

from gallop import chi2
from gallop import tensor_prep
from gallop import files


def seed_everything(seed=1234, change_backend=False):
    &#34;&#34;&#34;
    Set random seeds for everything.
    Note that at the moment, CUDA (which is used by PyTorch) is not
    deterministic for some operations and as a result, GALLOP runs from
    the same seed may still produce different result.
    See here for more details:
        https://pytorch.org/docs/stable/notes/randomness.html

    Args:
        seed (int, optional): Set the random seed to be used.
            Defaults to 1234.
        change_backend (bool, optional): Whether to change the backend used to
            try to make the code more reproducible. At the moment, it doesn&#39;t
            seem to help... default to False
    &#34;&#34;&#34;
    random.seed(seed)
    os.environ[&#39;PYTHONHASHSEED&#39;] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    if change_backend:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

def get_minimiser_settings(Structure):
    &#34;&#34;&#34;
    Get a dictionary of the settings used for the minimise function
    so it can be easily modified and passed to the function.

    Args:
        Structure (class): GALLOP structure

    Returns:
        dict: Dictionary of the settings for the minimise function
            Keys = n_reflections, include_dw_factors, chi2_solved, n_iterations,
            n_cooldown, learning_rate, learning_rate_schedule, verbose,
            use_progress_bar, print_every, check_min, dtype, device,
            ignore_reflections_for_chi2_calc, optimizer, loss, eps, save_CIF,
            streamlit
    &#34;&#34;&#34;
    settings = {}
    settings[&#34;n_reflections&#34;] = len(Structure.hkl)
    settings[&#34;include_dw_factors&#34;] = True
    settings[&#34;chi2_solved&#34;] = None
    settings[&#34;n_iterations&#34;] = 500
    settings[&#34;n_cooldown&#34;]   = 100
    settings[&#34;learning_rate&#34;] = 5e-2
    settings[&#34;learning_rate_schedule&#34;] = &#34;1cycle&#34;
    settings[&#34;verbose&#34;] = False
    settings[&#34;use_progress_bar&#34;] = True
    settings[&#34;print_every&#34;] = 100
    settings[&#34;check_min&#34;] = 100
    settings[&#34;dtype&#34;] = torch.float32
    settings[&#34;device&#34;] = None
    settings[&#34;ignore_reflections_for_chi2_calc&#34;] = False
    settings[&#34;optimizer&#34;] = &#34;adam&#34;
    settings[&#34;loss&#34;] = &#34;xlogx&#34;
    settings[&#34;eps&#34;] = 1e-8
    settings[&#34;save_CIF&#34;] = True
    settings[&#34;streamlit&#34;] = False
    return settings


def adjust_lr_1_over_sqrt(optimizer, iteration, learning_rate):
    &#34;&#34;&#34;
    Decay the learning_rate used in the local optimizer by 1/sqrt(iteration+1)
    Called by the minimise function

    Args:
        optimizer (pytorch optimizer): A pytorch compatible optimizer
        iteration (int): The current iteration
        learning_rate (float): The initial learning rate used

    Returns:
        float: the new learning rate
    &#34;&#34;&#34;
    lr = learning_rate * 1/np.sqrt((iteration)+1.)
    #lr = learning_rate * 1/np.sqrt((iteration/2.)+1.)
    for param_group in optimizer.param_groups:
        param_group[&#39;lr&#39;] = lr
    return lr

def adjust_lr_1_cycle(optimizer, iteration, low, high, final, num_iterations,
                        upperb1=0.95, lowb1=0.85, upperb2=0.9, lowb2=0.9):
    &#34;&#34;&#34;
    See here: https://sgugger.github.io/the-1cycle-policy.html

    Args:
        optimizer (pytorch optimizer): the optimizer object
        iteration (int): current learning rate
        low (float): initial learning rate
        high (float): maximum learning rate
        final (float): the cooldown iterations at the end of the run
        num_iterations (int): the number of iterations that will be performed
        upperb1 (float, optional): maximum beta1 / momentum. Defaults to 0.95.
        lowb1 (float, optional): minimum beta1 / momentum. Defaults to 0.85.
        upperb2 (float, optional): maximum beta2. Defaults to 0.9.
        lowb2 (float, optional): minimum beta2. Defaults to 0.9.

    Returns:
        float: the learning rate
    &#34;&#34;&#34;
    increment = (high-low)/(final//2)
    b1_increment = (upperb1 - lowb1) / (final//2)
    b2_increment = (upperb2 - lowb2) / (final//2)
    final_increment = low/(num_iterations-final)
    lr, b1, b2 = 0, 0, 0
    if iteration &lt; final//2:
        lr = increment*(iteration)+low
        b1 = upperb1 - b1_increment*iteration
        b2 = lowb2 + b2_increment*iteration
    elif iteration &lt;= final:
        lr = ((increment*(final//2))+low) - (increment*((iteration)-(final//2)))
        b1 = lowb1 + b1_increment*(iteration-(final//2))
        b2 = upperb2 - b2_increment*(iteration-(final//2))
    else:
        lr = low - (final_increment*(iteration-final))
        b1 = upperb1
        b2 = lowb2
    for param_group in optimizer.param_groups:
        param_group[&#39;lr&#39;] = lr
        param_group[&#39;betas&#39;] = [b1, b2]
        param_group[&#34;momentum&#34;] = b1
    return lr

def find_learning_rate(Structure, external=None, internal=None,
    min_lr=-4, max_lr=np.log10(0.15), n_trials=200, minimiser_settings=None,
    plot=False, multiplication_factor=0.75, logplot=True, figsize=(10,6)):
    &#34;&#34;&#34;
    See here: https://sgugger.github.io/the-1cycle-policy.html
    In contrast to the advice in the article (which is for training neural
    networks), in this work, it seems to work better to take the absolute
    minimum point that is obtained.

    Args:
        min_lr (int, optional): Minimum (log10) learning rate to try.
            Defaults to -5 (which is equivalent to 10^-4).
        max_lr (int, optional): Maximum (log10) learning rate to try.
            Defaults to log10(0.15).
        n_trials (int, optional): Number of trials between min_lr and max_lr.
            Defaults to 200.
        multiplication_factor (float, optional): multiply the lowest points
            in the learning rate curve by a fixed amount, e.g. 0.5 or 2.0 to
            decrease and increase the learning rate respectively. Defaults to 1.
        plot (bool, optional): Plot the curve of learning rate vs loss.
            Defaults to True.
        logplot (bool, optional): If plotting, use a logarithmic x-axis.
            Defaults to True.
        figsize (tuple, optional): The size of the figure. Defaults to (10,6)

    Returns:
        tuple: Tuple containing the trial learning rate values, the losses
                obtained and the learning rate associated with the minimum
                loss value
    &#34;&#34;&#34;

    if minimiser_settings is not None:
        # Set the learning rates to be tested
        trial_values = np.logspace(min_lr, max_lr, n_trials)
        lr_minimiser_settings = minimiser_settings.copy()
        lr_minimiser_settings[&#34;learning_rate&#34;] = trial_values
        lr_minimiser_settings[&#34;learning_rate_schedule&#34;] = &#34;array&#34;
        lr_minimiser_settings[&#34;n_iterations&#34;] = len(trial_values)
        lr_minimiser_settings[&#34;run&#34;] = -1
        lr_minimiser_settings[&#34;external&#34;] = external
        lr_minimiser_settings[&#34;internal&#34;] = internal
        lr_minimiser_settings[&#34;Structure&#34;] = Structure
        lr_minimiser_settings[&#34;save_CIF&#34;] = False
        lr_minimiser_settings[&#34;save_loss&#34;] = True


        # Get the losses at each learning rate
        result = minimise(**lr_minimiser_settings)

        losses = result[&#34;losses&#34;]


        if plot:
            plt.figure(figsize=figsize)
            plt.plot(trial_values, losses)
            if logplot:
                plt.xscale(&#39;log&#39;)
            plt.show()
        if multiplication_factor is None:
            minpoint = np.argmin(losses)
            final_1 = (trial_values[minpoint:]
                        - trial_values[minpoint:].min())[-1]
            final_0pt5 = 0.5 * final_1
            final_0pt25 = 0.25 * final_1
            if losses[-1] &lt; final_0pt25:
                multiplication_factor = 1.0
            elif losses[-1] &lt; final_0pt5:
                multiplication_factor = 0.75
            else:
                multiplication_factor = 0.5

        minimum_point = trial_values[losses == losses.min()][0]
        return trial_values, losses, multiplication_factor * minimum_point
    else:
        print(&#34;ERROR! Minimiser Settings are needed!&#34;)
        return None


def minimise(Structure, external=None, internal=None, n_samples=10000,
    n_iterations=500, n_cooldown=100, device=None, dtype=torch.float32,
    n_reflections=None, learning_rate_schedule=&#34;1cycle&#34;,
    b_bounds_1_cycle=None, check_min=1, optimizer=&#34;Adam&#34;, verbose=False, print_every=100,
    learning_rate=3e-2, betas=None, eps=1e-8, loss=&#34;sum&#34;, start_time=None,
    run=1, save_trajectories=False, save_grad=False, save_loss=False,
    include_dw_factors=True, chi2_solved=None,
    ignore_reflections_for_chi2_calc=False, use_progress_bar=True,
    save_CIF=True, streamlit=False):
    &#34;&#34;&#34;
    Main minimiser function used by GALLOP. Take a set of input external and
    internal degrees of freedom (as numpy arrays) together with the observed
    intensities and inverse covariance matrix, and optimise the chi-squared
    factor of agreement between the calculated and observed intensities.

    This forms one part of the GALLOP algorithm, the other part is a particle
    swarm optimisation step which is used to generate the starting positions
    that are passed to this minimisation function.

    Args:
        Structure (Structure object):   Contains all of the information about
            the crystal structure including PXRD data, Z-matrices, unit cell etc
        external (Numpy array, optional):   The external degrees of freedom for
            n_samples. Defaults to None. If None, then these will be randomly
            generated.
        internal (Numpy array, optional):   The internal degrees of freedom for
            n_samples. Defaults to None. If None, then these will be randomly
            generated.
        n_samples (int, optional):  If the external/internal DoFs are None,
            how many samples to generate. Defaults to 10000.
        n_iterations (int, optional): Total number of iterations to run the
            local-optimisation algorithm. Defaults to 500.
        n_cooldown (int, optional): Used in the 1-cycle learning rate policy.
            The number of iterations at the end of a local optimisation run with
            a low learning rate. Defaults to 100.
        device (torch.device, optional):    Where to run the calculations. If
            None, then check to see if a GPU exists and use it by default.
        dtype (torch datatype, optional): What datatype to use. Defaults to
            torch.float32.
        n_reflections (int, optional): The number of reflections to use for the
            chi_2 calculation. If None, use all available.
        learning_rate_schedule (str, optional): How to modify the learning rate
            during the optimisation process.
            One of: &#34;1cycle&#34;, &#34;sqrt&#34;, &#34;constant&#34;, &#34;array&#34;.
            &#34;1cycle&#34;    -   rapidly increase then decrease the learning rate,
                            before a &#34;cooldown&#34; period with a lower learning
                            rates. See this link for more details:
                            https://sgugger.github.io/the-1cycle-policy.html
            &#34;sqrt&#34;      -   decay the learning rate after each iteration
                            according to:
                                lr = learning_rate * 1/np.sqrt((iteration)+1.)
            &#34;constant&#34;  -   constant learning rate
            &#34;array&#34;     -   read the learning rate at each iteration from an
                            array
            Defaults to &#34;1cycle&#34;.
        learning_rate (Float or array, optional):   Depends on
            learning_rate_schedule. If float, then this is the initial learning
            rate used with the decay schedule. If an array, then the learing
            rate will be read from the array at each iteration.
            Defaults to 3e-2.
        b_bounds_1_cycle (dict, optional): Used in the 1cycle learning rate
            policy to set the upper and lower beta values. If set to None,
            then the following values will be used:
            {&#34;upperb1&#34;:0.95, &#34;lowb1&#34;:0.85, &#34;upperb2&#34;:0.9, &#34;lowb2&#34;:0.9}
        check_min (int, optional):  The number of iterations after which the
            best value of chi2 obtained so far is checked. Defaults to 1.
        optimizer (str or torch-compatible optimizer): Either a string or a
            torch-compatible optimizer. The only strings currently used are
            &#34;Adam&#34;, &#34;DiffGrad&#34; and &#34;Yogi&#34;.
        verbose (bool, optional): Print out information during the run.
            Defaults to False.
        print_every (int, optional):    If verbose is True, then how frequently
            to print out the information on the run progress. Also controls
            how often the best chi2 value is updated for the progress-bar.
        betas (list, optional): beta1 and beta2 values to use in Adam. Defaults
            to [0.9, 0.9] (if None set) which is equivalent to
            [beta1=0.9, beta2=0.9]
        eps (float, optional): Epsilon value to use in Adam or Adam derived
            optimizers. Defaults to 1e-8.
        loss (str or function, optional):   Pytorch requires a scalar to
            determine the gradients so the series of chi2 values obtained from
            the n_samples must be combined through some function before the
            gradient is determined. Different functions can be used to scaled
            the gradients in different ways. This may be advantageous if there
            is a significant difference in the magnitude of the gradient when
            chi2 is large vs when it is small. If string, must be one of:
            sum, sse, xlogx
                sum     -   add all the chi2 values together. The gradient for
                            each independent run will be the derivative of chi2
                            with respect to the degrees of freedom.
                sse     -   sum(chi2^2) (sum of squared errors). The gradient
                            for each independent run will be the derivative of
                            chi2 (wrt DoF) multiplied by 2*chi2.
                xlogx   -   sum(chi2 * log(chi2)). The gradient for each
                            independent run will be the derivative of chi2 (wrt
                            DoF) multiplied by log(chi2) + 1.
            If a function, this function must must take as input a pytorch
            tensor and return a scalar.
            Defaults to &#34;sum&#34;.
        start_time (time.time(), optional): The start time of a run or set of
            runs. Useful in full GALLOP runs, but if set to None then the start
            time will automatically be determined.
        run (int, optional): If a set of runs are being performed, then the run
            number can be passed for printing. Defaults to 1.
        save_trajectories (bool, optional): Store the DoF, chi_2 and loss value
            after every iteration. This will be slow, as it requires transfer
            from the GPU to CPU. Defaults to False.
        save_grad (bool, optional): Store the gradients of the internal and
            external DoF with respect to the chi_2 / loss values after every
            iteration. This will be slow, as it requires transfer from the GPU
            to CPU. Defaults to False.
        save_loss (bool, optional) : Save the value of the loss at each
            iteration. Used by find_learning_rate. Defaults to False.
        include_dw_factors (bool, optional): Include Debye-Waller factors in
            the intensity calculations. Defaults to True.
        chi2_solved (float, optional):  The value below which a structure is
            considered solved (if known). Used for some printed information.
            If None, then this is ignored. Defaults to None.
        ignore_reflections_for_chi2_calc (bool, optional):  The normal chi2
            calculation divides the output by (n_reflections - 2)
            i.e. chi2 = d.A.d / (n_reflections - 2)
            If set to True, this reverses this operation. Defaults to False.
        use_progress_bar (bool, optional): Use a progress bar to provide visual
            feedback on run progress. Defaults to True.
        save_CIF (bool, optional): Save a CIF of the best structure found
            after optimising. Defaults to True.
        streamlit (bool, optional): If using the streamlit webapp interface,
            this is set to True to enable a progress bar etc. Defaults to False

    Returns:
        dictionary: A dictionary containing the optimised external and internal
            degrees of freedom and their associated chi_2 values.
            If save_trajectories is True then this also contains the
            trajectories of the particles, the chi_2 values and loss values
            at each iteration.
    &#34;&#34;&#34;
    if b_bounds_1_cycle is None:
        b_bounds_1_cycle = {&#34;upperb1&#34;:0.95, &#34;lowb1&#34;:0.85, &#34;upperb2&#34;:0.9,
                            &#34;lowb2&#34;:0.9}
    if betas is None:
        betas = [0.9,0.9]
    if streamlit:
        import streamlit as st

    # Load the tensors and other parameters needed
    tensors = tensor_prep.get_all_required_tensors(
                                Structure, external=external, internal=internal,
                                n_samples=n_samples, device=device, dtype=dtype,
                                n_reflections=n_reflections, verbose=verbose,
                                include_dw_factors=include_dw_factors)
    trajectories = []
    gradients = []
    losses = []

    # Initialize the optimizer
    if isinstance(optimizer, str):
        if learning_rate_schedule.lower() == &#34;array&#34;:
            init_lr = learning_rate[0]
        else:
            init_lr = learning_rate
        if optimizer.lower() == &#34;adam&#34;:
            optimizer = torch.optim.Adam([tensors[&#34;external&#34;],
                                        tensors[&#34;internal&#34;]],
                                        lr=init_lr, betas=betas, eps=eps)
        elif optimizer.lower() == &#34;yogi&#34;:
            optimizer = t_optim.Yogi([tensors[&#34;external&#34;],
                                        tensors[&#34;internal&#34;]],
                                        lr=init_lr, betas=betas, eps=eps)
        elif optimizer.lower() == &#34;diffgrad&#34;:
            optimizer = t_optim.DiffGrad([tensors[&#34;external&#34;],
                                        tensors[&#34;internal&#34;]],
                                        lr=init_lr, betas=betas, eps=eps)
        else:
            print(&#34;Only supported optimizers are \&#34;Adam\&#34;, \&#34;DiffGrad\&#34; or&#34;,
            &#34;\&#34;Yogi\&#34;.&#34;)
            exit()
    else:
        # Ensure that the optimizer is a torch compatible optimizer that
        # accepts learning rate changes
        if not hasattr(optimizer, &#34;param_groups&#34;):
            print(&#34;Optimizer not compatible&#34;)
            exit()
        else:
            optimizer.param_groups[0][&#34;params&#34;] = [tensors[&#34;external&#34;],
                                                    tensors[&#34;internal&#34;]]
            for param_group in optimizer.param_groups:
                if learning_rate_schedule.lower() == &#34;array&#34;:
                    param_group[&#39;lr&#39;] = learning_rate[0]
                else:
                    param_group[&#39;lr&#39;] = learning_rate

    if start_time is None:
        t1 = time.time()
    else:
        t1 = start_time

    # Add the progress bar, if using
    if use_progress_bar and not streamlit:
        iters = tqdm.trange(n_iterations)
    else:
        iters = range(n_iterations)
        if streamlit:
            prog_bar = st.progress(0.0)

    # Now perform the optimisation iterations
    for i in iters:
        # Zero out gradient, else they will accumulate between iterations
        optimizer.zero_grad()

        if learning_rate_schedule.lower() == &#34;1cycle&#34;:
            lr = adjust_lr_1_cycle(optimizer, i, learning_rate/10,
                    learning_rate, n_iterations-n_cooldown, n_iterations,
                    **b_bounds_1_cycle)
        elif learning_rate_schedule.lower() == &#34;sqrt&#34;:
            lr = adjust_lr_1_over_sqrt(optimizer, i, learning_rate)
        elif learning_rate_schedule.lower() == &#34;constant&#34;:
            lr = learning_rate
        elif learning_rate_schedule.lower() == &#34;array&#34;:
            try:
                lr = learning_rate[i]
                for param_group in optimizer.param_groups:
                    param_group[&#39;lr&#39;] = lr
            except IndexError:
                print(&#34;Error in learning rate array&#34;)
                if len(learning_rate) &lt; i:
                    print(&#34;Insufficient entries in list, using last value&#34;)
                    lr = learning_rate[-1]
                else:
                    print(&#34;Check and try again&#34;)
                    exit()
        else:
            if i == 0:
                print(&#34;Learning rate scheduler unknown, using 1cycle&#34;)
                learning_rate_schedule=&#34;1cycle&#34;
                lr = adjust_lr_1_cycle(optimizer, i, learning_rate/10,
                        learning_rate, n_iterations-n_cooldown, n_iterations)
            else:
                print(&#34;An error has occurred with lr scheduling&#34;)

        # Forward pass - this gets a tensor of shape (n_samples, 1) with a
        # chi_2 value for each set of external/internal DoFs.
        chi_2 = chi2.get_chi_2(**tensors)
        if ignore_reflections_for_chi2_calc:
            # Counteract the division normally used in chi2 calculation
            chi_2 *= (tensors[&#34;hkl&#34;].shape[1] - 2)

        # PyTorch expects a single value for backwards pass.
        # Need a function to convert all of the chi_2 values into a scalar
        if isinstance(loss, str):
            if loss.lower() == &#34;sse&#34;:
                L = (chi_2**2).sum()
            elif loss.lower() == &#34;sum&#34;:
                L = chi_2.sum()
            elif loss.lower() == &#34;xlogx&#34;:
                L = torch.sum(chi_2*torch.log(chi_2))
        else:
            if loss is None:
                # Default to the sum operation if loss is None
                L = chi_2.sum()
            else:
                try:
                    L = loss(chi_2)
                except RuntimeError:
                    print(&#34;Unknown / incompatible loss function&#34;,loss)
                    print(&#34;Allowable arguments = sse (sum of squared errors),&#34;,
                        &#34;sum, xlogx or a suitable function that returns a&#34;,
                        &#34;single scalar value&#34;)

        # Backward pass to calculate gradients
        L.backward()
        if save_loss:
            losses.append(L.detach().cpu().numpy())
        if i == 0:
            best = torch.min(chi_2).item()
            best_iteration = 1
        else:
            if i % check_min == 0:
                if torch.min(chi_2).item() &lt; best:
                    best = torch.min(chi_2).item()
                    best_iteration = i
        i+=1
        if verbose:
            if i % print_every == 0 or i == 1:
                detached_chi2 = chi_2.detach().cpu().numpy()
                if chi2_solved is not None:
                    n_solved = detached_chi2[detached_chi2 &lt; chi2_solved]
                    printstring = (
                        &#34;GALLOP iter {:04d} | LO iter {:04d} | lr {:.3f} ||&#34;,
                        &#34;max/mean/min chi^2 {:.1f} / {:.1f} / {:.1f} ||&#34;,
                        &#34;Time {:.1f} (s) / {:.1f} (min) || Best {:.1f}&#34;,
                        &#34;in iter {:04d} || n&lt;{:.1f}: {:05d}&#34;)
                    print(&#34;&#34;.join(printstring).format(
                            run+1, i, lr,
                            chi_2.max().item(), chi_2.mean().item(),
                            chi_2.min().item(), time.time() - t1,
                            (time.time() - t1)/60, best, best_iteration,
                            chi2_solved, n_solved.shape[0]))
                else:
                    printstring = (
                        &#34;GALLOP iter {:04d} | LO iter {:04d} | lr {:.3f} ||&#34;,
                        &#34;max/mean/min chi^2 {:.1f} / {:.1f} / {:.1f} ||&#34;,
                        &#34;Time {:.1f} (s) / {:.1f} (min) || Best {:.1f}&#34;
                        &#34;in iter {:04d}&#34;)
                    print(&#34;&#34;.join(printstring).format(
                            run+1, i, lr,
                            chi_2.max().item(), chi_2.mean().item(),
                            chi_2.min().item(), time.time() - t1,
                            (time.time() - t1)/60, best,
                            best_iteration))
        elif use_progress_bar and not streamlit:
            if i % print_every == 0 or i == 1:
                iters.set_description(
                    &#34;GALLOP iter {:04d} LO iter {:04d} min chi2 {:.1f}&#34;.format(
                        run+1, i, chi_2.min().item()))
        if save_trajectories:
            trajectories.append([tensors[&#34;external&#34;].detach().cpu().numpy(),
                                tensors[&#34;internal&#34;].detach().cpu().numpy(),
                                chi_2.detach().cpu().numpy(),
                                L.detach().cpu().numpy()])
        if save_grad:
            gradients.append([tensors[&#34;external&#34;].grad.detach().cpu().numpy(),
                            tensors[&#34;internal&#34;].grad.detach().cpu().numpy()])
        if i != n_iterations:
            optimizer.step()
        if streamlit:
            prog_bar.progress(i/n_iterations)
    result = {
            &#34;external&#34;     : tensors[&#34;external&#34;].detach().cpu().numpy(),
            &#34;internal&#34;     : tensors[&#34;internal&#34;].detach().cpu().numpy(),
            &#34;chi_2&#34;        : chi_2.detach().cpu().numpy(),
            &#34;GALLOP Iter&#34;  : run
            }
    if save_CIF:
        files.save_CIF_of_best_result(Structure, result, start_time,
                                        n_reflections)
    if save_trajectories:
        result[&#34;trajectories&#34;] = trajectories
    if save_loss:
        result[&#34;losses&#34;] = np.array(losses)
    if save_grad:
        result[&#34;gradients&#34;] = gradients
    del tensors

    return result

def plot_torsion_difference(Structure, result, n_swarms=1,
    verbose=False, figsize=(10,10), xlim=None,
    ylim=None, cmap=&#34;tab20&#34;, call_show=True):
    &#34;&#34;&#34;
    Calculate the average difference between the known torsions (obtained
    from the Z-matrix input) to those obtained in an SDPD attempt.

    Torsion angles are first cast into the plane in order to account for the
    fact that 0 deg == 360 deg.

    Args:
        Structure (class): Structure object containing the true torsions,
            read in from the Z-matrices.
        result (dict): A result dict returned by the minimise function, which
            contains the internal DoF and the chi_2 values.
        n_swarms (int, optional): plot the separate swarms in different colours
            or set to 1 to plot all with the same colour. Defaults to 1.
        verbose (bool, optional): Print out information. Defaults to False.
        figsize (tuple, optional): Size of the plot. Defaults to (10,10).
        xlim (dict, optional): Limits of the x-axis.
            Defaults to {&#34;left&#34; : 0, &#34;right&#34; : None}.
        ylim (dict, optional): Limits of the y-axis.
            Defaults to {&#34;bottom&#34; : 0, &#34;top&#34; : None}.
        cmap (str, optional): the matplotlib colourmap to use.
            Defaults to tab20
        call_show (bool, optional): If True, will call plt.show() to render the
            plot. If False, the plot can be used in a subplot along with other
            plots by the user in the parent script or notebook.
    &#34;&#34;&#34;
    if xlim is None:
        xlim = {&#34;left&#34; : 0, &#34;right&#34; : None}
    if ylim is None:
        ylim = {&#34;bottom&#34; : 0, &#34;top&#34; : None}
    true_torsions = Structure.zm_torsions
    internal = result[&#34;internal&#34;]
    chi_2 = result[&#34;chi_2&#34;]
    subswarm = internal.shape[0] // n_swarms
    diff = true_torsions - internal
    sindiff = np.sin(diff)
    cosdiff = np.cos(diff)

    if verbose:
        if chi_2 is not None:
            mean_ang_diff = np.arctan2(sindiff.mean(axis=1),
                                        cosdiff.mean(axis=1))
            mean_ang_diff = (180/np.pi)*(mean_ang_diff)
            print(&#34;Mean diff, min mean diff, chi2 min mean diff&#34;)
            print(np.abs(mean_ang_diff).mean(), np.abs(mean_ang_diff).min(),
                                            mean_ang_diff[chi_2 == chi_2.min()])

    c_coord_diff = np.cos(true_torsions) - np.cos(internal)
    s_coord_diff = np.sin(true_torsions) - np.sin(internal)
    dist = np.sqrt((c_coord_diff**2 + s_coord_diff**2).mean(axis=1))
    if call_show:
        plt.figure(figsize=figsize)
    plt.scatter(chi_2, dist, s=10, cmap=cmap, alpha=0.75,
                    c=(np.arange(internal.shape[0])//subswarm))
    plt.xlim(**xlim)
    plt.ylim(**ylim)
    if call_show:
        plt.show()


class Swarm(object):
    def __init__(self, Structure, n_particles=10000, n_swarms=10,
        particle_best_position = None, best_chi_2 = None, velocity = None,
        position = None, best_subswarm_chi_2 = None, inertia=&#34;ranked&#34;, c1=1.5,
        c2=1.5, inertia_bounds=(0.4,0.9), use_matrix=True, limit_velocity=True,
        global_update=False, global_update_freq=10, vmax=1):
        &#34;&#34;&#34;
        Class for the particle swarm optimiser used in GALLOP.

        Args:
            Structure (class): GALLOP structure object
            n_particles (int, optional): The number of particles to optimise.
                Defaults to 10000.
            n_swarms (int, optional): The number of independent swarms which
                are represented by the n_particles. Defaults to 20.
            particle_best_position (numpy array, optional): the best position
                on the hypersurface obtained by each particle. Defaults to None.
            best_chi_2 (numpy array, optional): The best chi_2 obtained by each
                particle. Defaults to None.
            velocity (numpy array, optional): The current velocity of the
                particles. Defaults to None.
            position (numpy array, optional): The current position of the
                particles. Defaults to None.
            best_subswarm_chi_2 (list, optional): The best chi_2 found in each
                subswarm. Defaults to None.
            inertia (float or str, optional): The inertia to use in the velocity
                update. If random, sample the inertia from a uniform
                distribution. If &#34;ranked&#34;, then solutions ranked in order of
                increasing chi2. Lowest chi2 assigned lowest inertia, as defined
                by bounds in inertia_bounds. Defaults to &#34;ranked&#34;.
            c1 (int, optional): c1 (social) parameter in PSO equation.
                Defaults to 1.5
            c2 (int, optional): c2 (cognitive) parameter in PSO equation.
                Defaults to 1.5
            inertia_bounds (list, optional): The upper and lower bound of the
                values that inertia will take if inertia is set to &#34;random&#34; or
                &#34;ranked&#34;.
                Defaults to [0.4,0.9].
            use_matrix (bool, optional): Take a different step size in every
                degree of freedom. Defaults to True.
            limit_velocity (bool, optional): Restrict the velocity to the range
                (-vmax, vmax). Defaults to True.
            global_update (bool, optional): If True, allow global updates (see
                below). Defaults to False.
            global_update_freq (int, optional): If using subswarms, it may be
                desirable to occasionally update all subswarms swarm as a single
                swarm to allow communication of information from different
                regions of the hypersurface. Setting this to an integer will
                activate the global update when:
                    run number % global_update_freq == 0 and run number &gt; 0
                Defaults to 10.
            vmax (float, optional): The absolute maximum velocity a particle can
                achieve if limit_velocity is True.
        &#34;&#34;&#34;
        self.Structure = Structure
        self.particle_best_position = particle_best_position
        self.best_chi_2 = best_chi_2
        self.velocity = velocity
        self.position = position
        self.n_swarms = n_swarms
        self.best_subswarm_chi_2 = best_subswarm_chi_2
        self.inertia = inertia
        self.c1 = c1
        self.c2 = c2
        self.inertia_bounds = inertia_bounds
        self.use_matrix = use_matrix
        self.swarm_progress = []
        self.limit_velocity = limit_velocity
        self.n_particles = n_particles
        self.best_low_res_chi_2 = None
        self.best_high_res_chi_2 = None
        self.global_update = global_update
        self.global_update_freq = global_update_freq
        self.vmax = vmax
        self.best_subswarm_chi2 = []

    def get_initial_positions(self, method=&#34;latin&#34;, latin_criterion=None):
        &#34;&#34;&#34;
        Generate the initial starting points for a GALLOP attempt. The
        recommended method uses latin hypercube sampling which provides a
        more even coverage of the search space than random uniform sampling,
        which can produce clusters or leave regions unexplored.

        Args:
            method (str, optional): The sampling method to use. Can be one of
                &#34;latin&#34; or &#34;uniform&#34;. Defaults to &#34;latin&#34;.
            latin_criterion (str, optional): The criterion to be used with the
                latin hypercube method. See pyDOE documentation here:
                https://pythonhosted.org/pyDOE/randomized.html#latin-hypercube
                Defaults to None.

        Returns:
            tuple: Tuple of numpy arrays containing the initial external and
            internal degrees of freedom
        &#34;&#34;&#34;
        if self.Structure.total_internal_degrees_of_freedom is None:
            self.Structure.get_total_degrees_of_freedom()

        assert method in [&#34;uniform&#34;, &#34;latin&#34;], &#34;method must be latin or uniform&#34;
        if self.n_particles % self.n_swarms != 0:
            print(&#34;n_particles should be divisible by n_swarms.&#34;)
            self.n_particles = self.n_swarms * (self.n_particles//self.n_swarms)
            print(&#34;Setting n_particles to&#34;, self.n_particles)
        subswarm = self.n_particles // self.n_swarms
        init_external = []
        init_internal = []

        total_pos = self.Structure.total_position_degrees_of_freedom
        total_rot = self.Structure.total_rotation_degrees_of_freedom
        tot_external = total_pos+total_rot
        total_tors = self.Structure.total_internal_degrees_of_freedom
        # Separate hypercube for each subswarm
        for _ in tqdm.tqdm(range(self.n_swarms)):
            if method == &#34;latin&#34;:
                all_dof = np.array(pyDOE.lhs(total_pos + total_rot + total_tors,
                            samples=subswarm, criterion=latin_criterion))
                external = all_dof[:,:total_pos+total_rot]
                pos = external[:,:total_pos]
                rot = external[:,total_pos:]
                tor = all_dof[:,total_pos+total_rot:]
                rot -= 0.5
                rot *= 2. # Rotation to range [-1,1]
                tor -= 0.5
                tor *= 2. * np.pi # Torsions to range [-pi,pi]
                init_external.append(np.hstack([pos,rot]))
                init_internal.append(tor)

            else:
                rand_ext = np.random.uniform(-1,1,size=(subswarm,tot_external))
                rand_int = np.random.uniform(-1,1,size=(subswarm,total_tors))
                init_external.append(rand_ext)
                init_internal.append(rand_int)

        init_external = np.vstack(init_external)
        init_internal = np.vstack(init_internal)
        return init_external, init_internal


    def update_best(self, chi_2):
        &#34;&#34;&#34;
        Update the swarm with the best position and chi_2 for each particle

        Args:
            chi_2 (numpy array): the most recently obtained chi_2 values
        &#34;&#34;&#34;
        better = chi_2 &lt; self.best_chi_2
        self.particle_best_position[better] = self.position[better]
        self.best_chi_2[better] = chi_2[better]

    def get_position_from_dof(self, external, internal):
        &#34;&#34;&#34;
        Particle position values are unbounded, which can cause some issues
        with the swarm updates. This can be remedied in part by normalising
        all of the coordinates into the range -1 to +1.
        It also means that all of the coordinates will have the same range in
        the swarm, allowing easy comparison of exploration directions.

        For torsions, this is simple - merely take sin and cosine of the angles.
        For quaternions, ensuring that they are unit quaternions should do the
        trick.
        For the translations, this function uses the following:
            2 * ((translation % 1) - 0.5)

        Args:
            Structure (class): GALLOP structure which holds information about
                which indices of external and internal correspond to
                translations and rotations
            external (numpy array): External degrees of freedom
            internal (numpy array): Internal degrees of freedom

        Returns:
            numpy array : The normalised and stacked positions of the particles.
                Order is translation, rotation, torsion
        &#34;&#34;&#34;
        end_of_translations = self.Structure.total_position_degrees_of_freedom
        n_quaternions = self.Structure.total_rotation_degrees_of_freedom // 4
        translation = np.copy(external[:,:end_of_translations])
        translation = translation % 1    # Convert into range(0,1)
        translation *= 2 * np.pi         # Convert into range(0, 2pi)
        translation = np.hstack([np.sin(translation), np.cos(translation)])

        rotation = np.copy(external[:,end_of_translations:])
        rotation_list = []
        for i in range(n_quaternions):
            # Ensure quaternions are unit quaternions
            quaternion = rotation[:,(i*4):(i+1)*4]
            quaternion /= np.sqrt((quaternion**2).sum(axis=1)).reshape(-1,1)
            rotation_list.append(quaternion)
        rotation = np.hstack(rotation_list)
        # Take the sin and cos of the torsions, and stack everything.
        # Range for all parameters is now -1 to +1
        position = np.hstack([translation, rotation,
                                np.sin(internal), np.cos(internal)])

        return position


    def get_new_external_internal(self, position):
        &#34;&#34;&#34;
        Convert the swarm representation of position back to the external
        and internal degrees of freedom expected by GALLOP

        Args:
            position (numpy array): The internal swarm representation of the
                particle positions, where the positions and torsion angles have
                been projected onto the unit circle.

        Returns:
            tuple: Tuple of numpy arrays containing the external and internal
                degrees of freedom
        &#34;&#34;&#34;
        total_position = self.Structure.total_position_degrees_of_freedom
        total_rotation = self.Structure.total_rotation_degrees_of_freedom
        total_torsional = self.Structure.total_internal_degrees_of_freedom
        n_quaternions = total_rotation // 4
        end_external = (2*total_position) + total_rotation
        external = np.copy(position[:,:end_external])
        internal = np.copy(position[:,end_external:])
        # Reverse the normalisation of the particle position,
        # back to range 0 - 1
        pos_sines = external[:,:total_position]
        pos_cosines = external[:,total_position:2*total_position]
        # Can now use the inverse tangent to get positions in range -0.5, 0.5
        translations = np.arctan2(pos_sines, pos_cosines) / (2*np.pi)

        rotations = external[:,2*total_position:]
        rotation_list = []
        for i in range(n_quaternions):
            # Ensure the quaternions are unit quaternions
            quaternion = rotations[:,(i*4):(i+1)*4]
            quaternion /= np.sqrt((quaternion**2).sum(axis=1)).reshape(-1,1)
            rotation_list.append(quaternion)
        rotations = np.hstack(rotation_list)

        external = np.hstack([translations, rotations])
        # Revert torsion representation back to angles using the inverse tangent
        internal = np.arctan2(internal[:,:total_torsional],
                            internal[:,total_torsional:])

        return external, internal

    def PSO_velocity_update(self, previous_velocity, position,
        particle_best_pos, best_chi_2, inertia=&#34;random&#34;, c1=1.5, c2=1.5,
        inertia_bounds=(0.4,0.9), use_matrix=True):
        &#34;&#34;&#34;
        Update the velocity of the particles in the swarm

        Args:
            previous_velocity (numpy array): Current velocity
            position (numpy array): Current position
            particle_best_pos (numpy array): Best position for each particle
            best_chi_2 (numpy array): Best chi_2 for each particle
            inertia (str, numpy array or float, optional): Inertia to use.
                If string, can currently only be &#34;random&#34; or &#34;ranked&#34;.
                If random, then the inertia is randomly set for each particle
                within the bounds supplied in the parameter inertia_bounds.
                If &#34;ranked&#34;, then set the inertia values linearly between the
                bounds, with the lowest inertia for the best particle. If a
                float, then all particles are assigned the same inertia.
                Defaults to &#34;random&#34;.
            c1 (int, optional): c1 (social) parameter in PSO equation.
                Defaults to 1.5.
            c2 (int, optional): c2 (cognitive) parameter in PSO equation.
                Defaults to 1.5.
            inertia_bounds (tuple, optional): The upper and lower bound of the
                values that inertia can take if inertia is set to &#34;random&#34; or
                &#34;ranked&#34;. Defaults to (0.4,0.9)
            use_matrix (bool, optional): Take a different step size in every
                degree of freedom. Defaults to True.

        Returns:
            numpy array: The updated velocity of each particle
        &#34;&#34;&#34;
        global_best_pos = particle_best_pos[best_chi_2 == best_chi_2.min()]
        if global_best_pos.shape[0] &gt; 1:
            global_best_pos = global_best_pos[0]
        if (not isinstance(inertia, float)
                                    and not isinstance(inertia, np.ndarray)):
            if inertia.lower() == &#34;random&#34;:
                inertia = np.random.uniform(inertia_bounds[0],
                                        inertia_bounds[1],
                                        size=(previous_velocity.shape[0], 1))
            elif inertia.lower() == &#34;ranked&#34;:
                ranks = np.argsort(best_chi_2) + 1
                inertia = inertia_bounds[0] + (ranks * (inertia_bounds[1]
                                        - inertia_bounds[0]))/ranks.shape[0]
                inertia = inertia.reshape(-1,1)
            elif inertia.lower() == &#34;r_ranked&#34;:
                ranks = np.argsort(1/best_chi_2) + 1
                inertia = inertia_bounds[0] + (ranks * (inertia_bounds[1]
                                        - inertia_bounds[0]))/ranks.shape[0]
                inertia = inertia.reshape(-1,1)
            else:
                print(&#34;Unknown inertia type!&#34;, inertia)
                print(&#34;Setting inertia to 0.5&#34;)
                inertia = 0.5
        if use_matrix:
            R1 = np.random.uniform(0,1,size=(position.shape[0],
                                            position.shape[1]))
            R2 = np.random.uniform(0,1,size=(position.shape[0],
                                            position.shape[1]))
        else:
            R1 = np.random.uniform(0,1,size=(position.shape[0], 1))
            R2 = np.random.uniform(0,1,size=(position.shape[0], 1))

        new_velocity = (inertia*previous_velocity
                        + c1*R1*(global_best_pos - position)
                        + c2*R2*(particle_best_pos - position))

        return new_velocity

    def get_new_velocities(self, global_update=True, verbose=True):
        &#34;&#34;&#34;
        Update the particle velocities using the PSO equations.
        Can either update all particles as a single swarm, or treat them as a
        set of independent swarms (or subswarms).

        Args:
            global_update (bool, optional): If True, update all of the particles
                as a single swarm. If False, then update n_swarms separately.
                Defaults to True.
            verbose (bool, optional): Print out if a global update is being
                performed. Defaults to True.
        &#34;&#34;&#34;
        subswarm = self.n_particles // self.n_swarms
        use_ranked_all = False
        if isinstance(self.inertia, str):
            if self.inertia.lower() == &#34;ranked_all&#34;:
                ranks = np.argsort(self.best_chi_2) + 1
                ranked_inertia = (self.inertia_bounds[0]
                            + (ranks * (self.inertia_bounds[1]
                            - self.inertia_bounds[0]))/ranks.shape[0])
                ranked_inertia = ranked_inertia.reshape(-1,1)
                use_ranked_all = True
        if global_update:
            if verbose:
                print(&#34;Global&#34;)
            if use_ranked_all:
                self.velocity = self.PSO_velocity_update(self.velocity,
                                    self.position, self.particle_best_position,
                                    self.best_chi_2, inertia=ranked_inertia,
                                    c1=self.c1, c2=self.c2,
                                    inertia_bounds=self.inertia_bounds,
                                    use_matrix=self.use_matrix)
            else:
                self.velocity = self.PSO_velocity_update(self.velocity,
                                    self.position, self.particle_best_position,
                                    self.best_chi_2, inertia=self.inertia,
                                    c1=self.c1, c2=self.c2,
                                    inertia_bounds=self.inertia_bounds,
                                    use_matrix=self.use_matrix)
            for j in range(self.n_swarms):
                begin = j*subswarm
                end = (j+1)*subswarm
                self.best_subswarm_chi2.append(self.best_chi_2[begin:end].min())
            self.swarm_progress.append(self.best_subswarm_chi2)
        else:
            for j in range(self.n_swarms):
                begin = j*subswarm
                end = (j+1)*subswarm
                swarm_v = self.velocity[begin:end]
                swarm_pos = self.position[begin:end]
                swarm_best_pos = self.particle_best_position[begin:end]
                swarm_chi2 = self.best_chi_2[begin:end]
                if use_ranked_all:
                    swarm_ranked_inertia = ranked_inertia[begin:end]
                    new_vel = self.PSO_velocity_update(swarm_v, swarm_pos,
                            swarm_best_pos, swarm_chi2,
                            inertia=swarm_ranked_inertia,
                            c1=self.c1, c2=self.c2,
                            inertia_bounds=self.inertia_bounds,
                            use_matrix=self.use_matrix)
                else:
                    new_vel = self.PSO_velocity_update(swarm_v, swarm_pos,
                            swarm_best_pos, swarm_chi2, inertia=self.inertia,
                            c1=self.c1, c2=self.c2,
                            inertia_bounds=self.inertia_bounds,
                            use_matrix=self.use_matrix)
                self.velocity[begin:end] = new_vel
                self.best_subswarm_chi2.append(swarm_chi2.min())
            self.swarm_progress.append(self.best_subswarm_chi2)

        if self.limit_velocity:
            unlimited = self.velocity
            self.velocity[unlimited &gt; self.vmax] = self.vmax
            self.velocity[unlimited &lt; -1*self.vmax] = -1*self.vmax

    def update_position(self, result=None, external=None, internal=None,
        chi_2=None, run=None, global_update=False, verbose=True, n_swarms=None):
        &#34;&#34;&#34;
        Take a set of results from the minimisation algorithm and use
        them to generate a new set of starting points to be minimised. This
        will also update the internal swarm representation of position and
        velocity.

        Args:
            result (dict, optional): The result dict from a GALLOP minimise run.
                Defaults to None.
            external (numpy array, optional): If no result dict is supplied,
                then pass a numpy array of the external DoF. Defaults to None.
            internal (numpy array, optional): If no result dict is supplied,
                then pass a numpy array of the internal DoF. Defaults to None.
            chi_2 (numpy array, optional): If no result dict is supplied,
                then pass a numpy array of the chi_2 values. Defaults to None.
            run (int, optional): If no result dict is supplied, then pass the
                run number. Defaults to None.
            global_update (bool, optional): If True, update all of the particles
                as a single swarm. Defaults to False.
            verbose (bool, optional): Print out information. Defaults to True.
            n_swarms (int, optional): If global_update is False, it use the
                Swarm.n_swarms parameter. This value can be overwritten if
                desired by supplying it as an argument. This could be useful for
                strategies that enable small subswarms to communicate, e.g.
                initially have 2^n swarms, then after some iterations, change to
                2^(n-1) swarms for 1 or more iterations. This would propagate
                information between swarms without doing a full global update.
                Defaults to None.

        Returns:
            tuple: Tuple of numpy arrays containing the external and internal
                degrees of freedom
        &#34;&#34;&#34;
        if result is not None:
            external = result[&#34;external&#34;]
            internal = result[&#34;internal&#34;]
            chi_2 = result[&#34;chi_2&#34;]
            run = result[&#34;GALLOP Iter&#34;]
        else:
            if external is None and internal is None:
                print(&#34;No DoFs supplied!&#34;)
                exit()
        self.position = self.get_position_from_dof(external, internal)
        if self.n_particles is None:
            self.n_particles = external.shape[0]

        if n_swarms is not None:
            self.n_swarms = n_swarms

        if self.particle_best_position is None:
            self.particle_best_position = np.copy(self.position)
            self.best_chi_2 = np.copy(chi_2)
        if self.velocity is None:
            self.velocity = np.zeros_like(self.position)
        self.update_best(chi_2)

        if not global_update:
            if self.global_update_freq is not None and self.global_update:
                if (run+1) % self.global_update_freq == 0 and run != 0:
                    global_update = True
        self.get_new_velocities(global_update=global_update, verbose=verbose)
        self.position = self.position + self.velocity

        if verbose:
            print(self.velocity.min(), self.velocity.max(),
            self.velocity.mean(),
            self.velocity.std(), np.abs(self.velocity).mean(),
            np.abs(self.velocity).std())

        external, internal = self.get_new_external_internal(self.position)

        return external, internal

    def get_CIF_of_best(self, n_reflections=None, one_for_each_subswarm=True,
                                filename_root=None, run=None, start_time=None):
        &#34;&#34;&#34;
        Get a CIF of the best results found by the particle swarm

        Args:
            n_reflections (int, optional): The number of reflections used in the
                SDPD attempts. May be useful if comparing resolutions, but not
                normally needed. If None, then n_reflections = all reflections.
                Defaults to None.
            one_for_each_subswarm (bool, optional): A separate CIF for every
                independent subswarm rather than just the best globally.
                Defaults to True.
            filename_root (str, optional): Specify the root filename to use.
                If None, then use the structure name as the root.
                Defaults to None.
            run (int, optional): The GALLOP iteration. Defaults to None.
            start_time (float, optional): A float produced by time.time() that
                indicates when the run started. Defaults to None.
        &#34;&#34;&#34;
        if not one_for_each_subswarm:
            external, internal = self.get_new_external_internal(
                                                    self.particle_best_position)
            chi_2 = self.best_chi_2
            external = external[chi_2 == chi_2.min()]
            internal = internal[chi_2 == chi_2.min()]
            if external.shape[0] &gt; 1:
                external = external[0]
                internal = internal[0]
            chi_2 = chi_2.min()
            external = external.reshape(1,-1)
            internal = internal.reshape(1,-1)
        else:
            positions, chi2s = [], []
            for i in range(self.n_swarms):
                subswarm = self.n_particles // self.n_swarms
                begin = i*subswarm
                end = (i+1)*subswarm
                swarm_best_pos = self.particle_best_position[begin:end]
                swarm_chi2 = self.best_chi_2[begin:end]
                best_pos = swarm_best_pos[swarm_chi2 == swarm_chi2.min()]
                # If more than one particle has the same chi2, only save one
                # of them.
                if best_pos.shape[0] &gt; 1:
                    best_pos = best_pos[0].reshape(1,-1)
                best_chi_2 = swarm_chi2.min()
                positions.append(best_pos)
                chi2s.append(best_chi_2)
            positions = np.vstack(positions)
            chi2s = np.array(chi2s)
            external, internal = self.get_new_external_internal(positions)
        if filename_root is None:
            filename_root = self.Structure.name
        for i in range(external.shape[0]):
            result = {}
            result[&#34;external&#34;] = external[i]
            result[&#34;internal&#34;] = internal[i]
            result[&#34;chi_2&#34;] = chi2s[i]
            if run is None:
                result[&#34;GALLOP Iter&#34;] = len(self.swarm_progress)
            else:
                result[&#34;GALLOP Iter&#34;] = run
            if start_time is None:
                start_time = time.time()
            files.save_CIF_of_best_result(self.Structure, result, start_time,
                                    n_reflections, filename_root=filename_root
                                    +&#34;_swarm_&#34;+str(i))

    def reset_position_and_velocity(self):
        &#34;&#34;&#34;
        Reset the Particle swarm
        &#34;&#34;&#34;
        self.particle_best_position = None
        self.n_particles = None
        self.velocity = None</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="gallop.optimiser.adjust_lr_1_cycle"><code class="name flex">
<span>def <span class="ident">adjust_lr_1_cycle</span></span>(<span>optimizer, iteration, low, high, final, num_iterations, upperb1=0.95, lowb1=0.85, upperb2=0.9, lowb2=0.9)</span>
</code></dt>
<dd>
<div class="desc"><p>See here: <a href="https://sgugger.github.io/the-1cycle-policy.html">https://sgugger.github.io/the-1cycle-policy.html</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>pytorch optimizer</code></dt>
<dd>the optimizer object</dd>
<dt><strong><code>iteration</code></strong> :&ensp;<code>int</code></dt>
<dd>current learning rate</dd>
<dt><strong><code>low</code></strong> :&ensp;<code>float</code></dt>
<dd>initial learning rate</dd>
<dt><strong><code>high</code></strong> :&ensp;<code>float</code></dt>
<dd>maximum learning rate</dd>
<dt><strong><code>final</code></strong> :&ensp;<code>float</code></dt>
<dd>the cooldown iterations at the end of the run</dd>
<dt><strong><code>num_iterations</code></strong> :&ensp;<code>int</code></dt>
<dd>the number of iterations that will be performed</dd>
<dt><strong><code>upperb1</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>maximum beta1 / momentum. Defaults to 0.95.</dd>
<dt><strong><code>lowb1</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>minimum beta1 / momentum. Defaults to 0.85.</dd>
<dt><strong><code>upperb2</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>maximum beta2. Defaults to 0.9.</dd>
<dt><strong><code>lowb2</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>minimum beta2. Defaults to 0.9.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>the learning rate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_lr_1_cycle(optimizer, iteration, low, high, final, num_iterations,
                        upperb1=0.95, lowb1=0.85, upperb2=0.9, lowb2=0.9):
    &#34;&#34;&#34;
    See here: https://sgugger.github.io/the-1cycle-policy.html

    Args:
        optimizer (pytorch optimizer): the optimizer object
        iteration (int): current learning rate
        low (float): initial learning rate
        high (float): maximum learning rate
        final (float): the cooldown iterations at the end of the run
        num_iterations (int): the number of iterations that will be performed
        upperb1 (float, optional): maximum beta1 / momentum. Defaults to 0.95.
        lowb1 (float, optional): minimum beta1 / momentum. Defaults to 0.85.
        upperb2 (float, optional): maximum beta2. Defaults to 0.9.
        lowb2 (float, optional): minimum beta2. Defaults to 0.9.

    Returns:
        float: the learning rate
    &#34;&#34;&#34;
    increment = (high-low)/(final//2)
    b1_increment = (upperb1 - lowb1) / (final//2)
    b2_increment = (upperb2 - lowb2) / (final//2)
    final_increment = low/(num_iterations-final)
    lr, b1, b2 = 0, 0, 0
    if iteration &lt; final//2:
        lr = increment*(iteration)+low
        b1 = upperb1 - b1_increment*iteration
        b2 = lowb2 + b2_increment*iteration
    elif iteration &lt;= final:
        lr = ((increment*(final//2))+low) - (increment*((iteration)-(final//2)))
        b1 = lowb1 + b1_increment*(iteration-(final//2))
        b2 = upperb2 - b2_increment*(iteration-(final//2))
    else:
        lr = low - (final_increment*(iteration-final))
        b1 = upperb1
        b2 = lowb2
    for param_group in optimizer.param_groups:
        param_group[&#39;lr&#39;] = lr
        param_group[&#39;betas&#39;] = [b1, b2]
        param_group[&#34;momentum&#34;] = b1
    return lr</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.adjust_lr_1_over_sqrt"><code class="name flex">
<span>def <span class="ident">adjust_lr_1_over_sqrt</span></span>(<span>optimizer, iteration, learning_rate)</span>
</code></dt>
<dd>
<div class="desc"><p>Decay the learning_rate used in the local optimizer by 1/sqrt(iteration+1)
Called by the minimise function</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>pytorch optimizer</code></dt>
<dd>A pytorch compatible optimizer</dd>
<dt><strong><code>iteration</code></strong> :&ensp;<code>int</code></dt>
<dd>The current iteration</dd>
<dt><strong><code>learning_rate</code></strong> :&ensp;<code>float</code></dt>
<dd>The initial learning rate used</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>the new learning rate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def adjust_lr_1_over_sqrt(optimizer, iteration, learning_rate):
    &#34;&#34;&#34;
    Decay the learning_rate used in the local optimizer by 1/sqrt(iteration+1)
    Called by the minimise function

    Args:
        optimizer (pytorch optimizer): A pytorch compatible optimizer
        iteration (int): The current iteration
        learning_rate (float): The initial learning rate used

    Returns:
        float: the new learning rate
    &#34;&#34;&#34;
    lr = learning_rate * 1/np.sqrt((iteration)+1.)
    #lr = learning_rate * 1/np.sqrt((iteration/2.)+1.)
    for param_group in optimizer.param_groups:
        param_group[&#39;lr&#39;] = lr
    return lr</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.find_learning_rate"><code class="name flex">
<span>def <span class="ident">find_learning_rate</span></span>(<span>Structure, external=None, internal=None, min_lr=-4, max_lr=-0.8239087409443188, n_trials=200, minimiser_settings=None, plot=False, multiplication_factor=0.75, logplot=True, figsize=(10, 6))</span>
</code></dt>
<dd>
<div class="desc"><p>See here: <a href="https://sgugger.github.io/the-1cycle-policy.html">https://sgugger.github.io/the-1cycle-policy.html</a>
In contrast to the advice in the article (which is for training neural
networks), in this work, it seems to work better to take the absolute
minimum point that is obtained.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>min_lr</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Minimum (log10) learning rate to try.
Defaults to -5 (which is equivalent to 10^-4).</dd>
<dt><strong><code>max_lr</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum (log10) learning rate to try.
Defaults to log10(0.15).</dd>
<dt><strong><code>n_trials</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of trials between min_lr and max_lr.
Defaults to 200.</dd>
<dt><strong><code>multiplication_factor</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>multiply the lowest points
in the learning rate curve by a fixed amount, e.g. 0.5 or 2.0 to
decrease and increase the learning rate respectively. Defaults to 1.</dd>
<dt><strong><code>plot</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Plot the curve of learning rate vs loss.
Defaults to True.</dd>
<dt><strong><code>logplot</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If plotting, use a logarithmic x-axis.
Defaults to True.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>The size of the figure. Defaults to (10,6)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Tuple containing the trial learning rate values, the losses
obtained and the learning rate associated with the minimum
loss value</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_learning_rate(Structure, external=None, internal=None,
    min_lr=-4, max_lr=np.log10(0.15), n_trials=200, minimiser_settings=None,
    plot=False, multiplication_factor=0.75, logplot=True, figsize=(10,6)):
    &#34;&#34;&#34;
    See here: https://sgugger.github.io/the-1cycle-policy.html
    In contrast to the advice in the article (which is for training neural
    networks), in this work, it seems to work better to take the absolute
    minimum point that is obtained.

    Args:
        min_lr (int, optional): Minimum (log10) learning rate to try.
            Defaults to -5 (which is equivalent to 10^-4).
        max_lr (int, optional): Maximum (log10) learning rate to try.
            Defaults to log10(0.15).
        n_trials (int, optional): Number of trials between min_lr and max_lr.
            Defaults to 200.
        multiplication_factor (float, optional): multiply the lowest points
            in the learning rate curve by a fixed amount, e.g. 0.5 or 2.0 to
            decrease and increase the learning rate respectively. Defaults to 1.
        plot (bool, optional): Plot the curve of learning rate vs loss.
            Defaults to True.
        logplot (bool, optional): If plotting, use a logarithmic x-axis.
            Defaults to True.
        figsize (tuple, optional): The size of the figure. Defaults to (10,6)

    Returns:
        tuple: Tuple containing the trial learning rate values, the losses
                obtained and the learning rate associated with the minimum
                loss value
    &#34;&#34;&#34;

    if minimiser_settings is not None:
        # Set the learning rates to be tested
        trial_values = np.logspace(min_lr, max_lr, n_trials)
        lr_minimiser_settings = minimiser_settings.copy()
        lr_minimiser_settings[&#34;learning_rate&#34;] = trial_values
        lr_minimiser_settings[&#34;learning_rate_schedule&#34;] = &#34;array&#34;
        lr_minimiser_settings[&#34;n_iterations&#34;] = len(trial_values)
        lr_minimiser_settings[&#34;run&#34;] = -1
        lr_minimiser_settings[&#34;external&#34;] = external
        lr_minimiser_settings[&#34;internal&#34;] = internal
        lr_minimiser_settings[&#34;Structure&#34;] = Structure
        lr_minimiser_settings[&#34;save_CIF&#34;] = False
        lr_minimiser_settings[&#34;save_loss&#34;] = True


        # Get the losses at each learning rate
        result = minimise(**lr_minimiser_settings)

        losses = result[&#34;losses&#34;]


        if plot:
            plt.figure(figsize=figsize)
            plt.plot(trial_values, losses)
            if logplot:
                plt.xscale(&#39;log&#39;)
            plt.show()
        if multiplication_factor is None:
            minpoint = np.argmin(losses)
            final_1 = (trial_values[minpoint:]
                        - trial_values[minpoint:].min())[-1]
            final_0pt5 = 0.5 * final_1
            final_0pt25 = 0.25 * final_1
            if losses[-1] &lt; final_0pt25:
                multiplication_factor = 1.0
            elif losses[-1] &lt; final_0pt5:
                multiplication_factor = 0.75
            else:
                multiplication_factor = 0.5

        minimum_point = trial_values[losses == losses.min()][0]
        return trial_values, losses, multiplication_factor * minimum_point
    else:
        print(&#34;ERROR! Minimiser Settings are needed!&#34;)
        return None</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.get_minimiser_settings"><code class="name flex">
<span>def <span class="ident">get_minimiser_settings</span></span>(<span>Structure)</span>
</code></dt>
<dd>
<div class="desc"><p>Get a dictionary of the settings used for the minimise function
so it can be easily modified and passed to the function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Structure</code></strong> :&ensp;<code>class</code></dt>
<dd>GALLOP structure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Dictionary of the settings for the minimise function
Keys = n_reflections, include_dw_factors, chi2_solved, n_iterations,
n_cooldown, learning_rate, learning_rate_schedule, verbose,
use_progress_bar, print_every, check_min, dtype, device,
ignore_reflections_for_chi2_calc, optimizer, loss, eps, save_CIF,
streamlit</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_minimiser_settings(Structure):
    &#34;&#34;&#34;
    Get a dictionary of the settings used for the minimise function
    so it can be easily modified and passed to the function.

    Args:
        Structure (class): GALLOP structure

    Returns:
        dict: Dictionary of the settings for the minimise function
            Keys = n_reflections, include_dw_factors, chi2_solved, n_iterations,
            n_cooldown, learning_rate, learning_rate_schedule, verbose,
            use_progress_bar, print_every, check_min, dtype, device,
            ignore_reflections_for_chi2_calc, optimizer, loss, eps, save_CIF,
            streamlit
    &#34;&#34;&#34;
    settings = {}
    settings[&#34;n_reflections&#34;] = len(Structure.hkl)
    settings[&#34;include_dw_factors&#34;] = True
    settings[&#34;chi2_solved&#34;] = None
    settings[&#34;n_iterations&#34;] = 500
    settings[&#34;n_cooldown&#34;]   = 100
    settings[&#34;learning_rate&#34;] = 5e-2
    settings[&#34;learning_rate_schedule&#34;] = &#34;1cycle&#34;
    settings[&#34;verbose&#34;] = False
    settings[&#34;use_progress_bar&#34;] = True
    settings[&#34;print_every&#34;] = 100
    settings[&#34;check_min&#34;] = 100
    settings[&#34;dtype&#34;] = torch.float32
    settings[&#34;device&#34;] = None
    settings[&#34;ignore_reflections_for_chi2_calc&#34;] = False
    settings[&#34;optimizer&#34;] = &#34;adam&#34;
    settings[&#34;loss&#34;] = &#34;xlogx&#34;
    settings[&#34;eps&#34;] = 1e-8
    settings[&#34;save_CIF&#34;] = True
    settings[&#34;streamlit&#34;] = False
    return settings</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.minimise"><code class="name flex">
<span>def <span class="ident">minimise</span></span>(<span>Structure, external=None, internal=None, n_samples=10000, n_iterations=500, n_cooldown=100, device=None, dtype=torch.float32, n_reflections=None, learning_rate_schedule='1cycle', b_bounds_1_cycle=None, check_min=1, optimizer='Adam', verbose=False, print_every=100, learning_rate=0.03, betas=None, eps=1e-08, loss='sum', start_time=None, run=1, save_trajectories=False, save_grad=False, save_loss=False, include_dw_factors=True, chi2_solved=None, ignore_reflections_for_chi2_calc=False, use_progress_bar=True, save_CIF=True, streamlit=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Main minimiser function used by GALLOP. Take a set of input external and
internal degrees of freedom (as numpy arrays) together with the observed
intensities and inverse covariance matrix, and optimise the chi-squared
factor of agreement between the calculated and observed intensities.</p>
<p>This forms one part of the GALLOP algorithm, the other part is a particle
swarm optimisation step which is used to generate the starting positions
that are passed to this minimisation function.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Structure</code></strong> :&ensp;<code>Structure object</code></dt>
<dd>Contains all of the information about
the crystal structure including PXRD data, Z-matrices, unit cell etc</dd>
<dt><strong><code>external</code></strong> :&ensp;<code>Numpy array</code>, optional</dt>
<dd>The external degrees of freedom for
n_samples. Defaults to None. If None, then these will be randomly
generated.</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>Numpy array</code>, optional</dt>
<dd>The internal degrees of freedom for
n_samples. Defaults to None. If None, then these will be randomly
generated.</dd>
<dt><strong><code>n_samples</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If the external/internal DoFs are None,
how many samples to generate. Defaults to 10000.</dd>
<dt><strong><code>n_iterations</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Total number of iterations to run the
local-optimisation algorithm. Defaults to 500.</dd>
<dt><strong><code>n_cooldown</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Used in the 1-cycle learning rate policy.
The number of iterations at the end of a local optimisation run with
a low learning rate. Defaults to 100.</dd>
<dt><strong><code>device</code></strong> :&ensp;<code>torch.device</code>, optional</dt>
<dd>Where to run the calculations. If
None, then check to see if a GPU exists and use it by default.</dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>torch datatype</code>, optional</dt>
<dd>What datatype to use. Defaults to
torch.float32.</dd>
<dt><strong><code>n_reflections</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of reflections to use for the
chi_2 calculation. If None, use all available.</dd>
<dt><strong><code>learning_rate_schedule</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>How to modify the learning rate
during the optimisation process.
One of: "1cycle", "sqrt", "constant", "array".
"1cycle"
-
rapidly increase then decrease the learning rate,
before a "cooldown" period with a lower learning
rates. See this link for more details:
<a href="https://sgugger.github.io/the-1cycle-policy.html">https://sgugger.github.io/the-1cycle-policy.html</a>
"sqrt"
-
decay the learning rate after each iteration
according to:
lr = learning_rate * 1/np.sqrt((iteration)+1.)
"constant"
-
constant learning rate
"array"
-
read the learning rate at each iteration from an
array
Defaults to "1cycle".</dd>
<dt><strong><code>learning_rate</code></strong> :&ensp;<code>Float</code> or <code>array</code>, optional</dt>
<dd>Depends on
learning_rate_schedule. If float, then this is the initial learning
rate used with the decay schedule. If an array, then the learing
rate will be read from the array at each iteration.
Defaults to 3e-2.</dd>
<dt><strong><code>b_bounds_1_cycle</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd _lowb1_:0.85_="&quot;lowb1&quot;:0.85," _lowb2_:0.9="&quot;lowb2&quot;:0.9" _upperb1_:0.95_="&quot;upperb1&quot;:0.95," _upperb2_:0.9_="&quot;upperb2&quot;:0.9,">Used in the 1cycle learning rate
policy to set the upper and lower beta values. If set to None,
then the following values will be used:</dd>
<dt><strong><code>check_min</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of iterations after which the
best value of chi2 obtained so far is checked. Defaults to 1.</dd>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>str</code> or <code>torch-compatible optimizer</code></dt>
<dd>Either a string or a
torch-compatible optimizer. The only strings currently used are
"Adam", "DiffGrad" and "Yogi".</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print out information during the run.
Defaults to False.</dd>
<dt><strong><code>print_every</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If verbose is True, then how frequently
to print out the information on the run progress. Also controls
how often the best chi2 value is updated for the progress-bar.</dd>
<dt><strong><code>betas</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>beta1 and beta2 values to use in Adam. Defaults
to [0.9, 0.9] (if None set) which is equivalent to
[beta1=0.9, beta2=0.9]</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Epsilon value to use in Adam or Adam derived
optimizers. Defaults to 1e-8.</dd>
<dt><strong><code>loss</code></strong> :&ensp;<code>str</code> or <code>function</code>, optional</dt>
<dd>Pytorch requires a scalar to
determine the gradients so the series of chi2 values obtained from
the n_samples must be combined through some function before the
gradient is determined. Different functions can be used to scaled
the gradients in different ways. This may be advantageous if there
is a significant difference in the magnitude of the gradient when
chi2 is large vs when it is small. If string, must be one of:
sum, sse, xlogx
sum
-
add all the chi2 values together. The gradient for
each independent run will be the derivative of chi2
with respect to the degrees of freedom.
sse
-
sum(chi2^2) (sum of squared errors). The gradient
for each independent run will be the derivative of
chi2 (wrt DoF) multiplied by 2*chi2.
xlogx
-
sum(chi2 * log(chi2)). The gradient for each
independent run will be the derivative of chi2 (wrt
DoF) multiplied by log(chi2) + 1.
If a function, this function must must take as input a pytorch
tensor and return a scalar.
Defaults to "sum".</dd>
<dt>start_time (time.time(), optional): The start time of a run or set of</dt>
<dt>runs. Useful in full GALLOP runs, but if set to None then the start</dt>
<dt>time will automatically be determined.</dt>
<dt><strong><code>run</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If a set of runs are being performed, then the run
number can be passed for printing. Defaults to 1.</dd>
<dt><strong><code>save_trajectories</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Store the DoF, chi_2 and loss value
after every iteration. This will be slow, as it requires transfer
from the GPU to CPU. Defaults to False.</dd>
<dt><strong><code>save_grad</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Store the gradients of the internal and
external DoF with respect to the chi_2 / loss values after every
iteration. This will be slow, as it requires transfer from the GPU
to CPU. Defaults to False.</dd>
<dt>save_loss (bool, optional) : Save the value of the loss at each</dt>
<dt>iteration. Used by find_learning_rate. Defaults to False.</dt>
<dt><strong><code>include_dw_factors</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Include Debye-Waller factors in
the intensity calculations. Defaults to True.</dd>
<dt><strong><code>chi2_solved</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The value below which a structure is
considered solved (if known). Used for some printed information.
If None, then this is ignored. Defaults to None.</dd>
<dt><strong><code>ignore_reflections_for_chi2_calc</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>The normal chi2
calculation divides the output by (n_reflections - 2)
i.e. chi2 = d.A.d / (n_reflections - 2)
If set to True, this reverses this operation. Defaults to False.</dd>
<dt><strong><code>use_progress_bar</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Use a progress bar to provide visual
feedback on run progress. Defaults to True.</dd>
<dt><strong><code>save_CIF</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Save a CIF of the best structure found
after optimising. Defaults to True.</dd>
<dt><strong><code>streamlit</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If using the streamlit webapp interface,
this is set to True to enable a progress bar etc. Defaults to False</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dictionary</code></dt>
<dd>A dictionary containing the optimised external and internal
degrees of freedom and their associated chi_2 values.
If save_trajectories is True then this also contains the
trajectories of the particles, the chi_2 values and loss values
at each iteration.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def minimise(Structure, external=None, internal=None, n_samples=10000,
    n_iterations=500, n_cooldown=100, device=None, dtype=torch.float32,
    n_reflections=None, learning_rate_schedule=&#34;1cycle&#34;,
    b_bounds_1_cycle=None, check_min=1, optimizer=&#34;Adam&#34;, verbose=False, print_every=100,
    learning_rate=3e-2, betas=None, eps=1e-8, loss=&#34;sum&#34;, start_time=None,
    run=1, save_trajectories=False, save_grad=False, save_loss=False,
    include_dw_factors=True, chi2_solved=None,
    ignore_reflections_for_chi2_calc=False, use_progress_bar=True,
    save_CIF=True, streamlit=False):
    &#34;&#34;&#34;
    Main minimiser function used by GALLOP. Take a set of input external and
    internal degrees of freedom (as numpy arrays) together with the observed
    intensities and inverse covariance matrix, and optimise the chi-squared
    factor of agreement between the calculated and observed intensities.

    This forms one part of the GALLOP algorithm, the other part is a particle
    swarm optimisation step which is used to generate the starting positions
    that are passed to this minimisation function.

    Args:
        Structure (Structure object):   Contains all of the information about
            the crystal structure including PXRD data, Z-matrices, unit cell etc
        external (Numpy array, optional):   The external degrees of freedom for
            n_samples. Defaults to None. If None, then these will be randomly
            generated.
        internal (Numpy array, optional):   The internal degrees of freedom for
            n_samples. Defaults to None. If None, then these will be randomly
            generated.
        n_samples (int, optional):  If the external/internal DoFs are None,
            how many samples to generate. Defaults to 10000.
        n_iterations (int, optional): Total number of iterations to run the
            local-optimisation algorithm. Defaults to 500.
        n_cooldown (int, optional): Used in the 1-cycle learning rate policy.
            The number of iterations at the end of a local optimisation run with
            a low learning rate. Defaults to 100.
        device (torch.device, optional):    Where to run the calculations. If
            None, then check to see if a GPU exists and use it by default.
        dtype (torch datatype, optional): What datatype to use. Defaults to
            torch.float32.
        n_reflections (int, optional): The number of reflections to use for the
            chi_2 calculation. If None, use all available.
        learning_rate_schedule (str, optional): How to modify the learning rate
            during the optimisation process.
            One of: &#34;1cycle&#34;, &#34;sqrt&#34;, &#34;constant&#34;, &#34;array&#34;.
            &#34;1cycle&#34;    -   rapidly increase then decrease the learning rate,
                            before a &#34;cooldown&#34; period with a lower learning
                            rates. See this link for more details:
                            https://sgugger.github.io/the-1cycle-policy.html
            &#34;sqrt&#34;      -   decay the learning rate after each iteration
                            according to:
                                lr = learning_rate * 1/np.sqrt((iteration)+1.)
            &#34;constant&#34;  -   constant learning rate
            &#34;array&#34;     -   read the learning rate at each iteration from an
                            array
            Defaults to &#34;1cycle&#34;.
        learning_rate (Float or array, optional):   Depends on
            learning_rate_schedule. If float, then this is the initial learning
            rate used with the decay schedule. If an array, then the learing
            rate will be read from the array at each iteration.
            Defaults to 3e-2.
        b_bounds_1_cycle (dict, optional): Used in the 1cycle learning rate
            policy to set the upper and lower beta values. If set to None,
            then the following values will be used:
            {&#34;upperb1&#34;:0.95, &#34;lowb1&#34;:0.85, &#34;upperb2&#34;:0.9, &#34;lowb2&#34;:0.9}
        check_min (int, optional):  The number of iterations after which the
            best value of chi2 obtained so far is checked. Defaults to 1.
        optimizer (str or torch-compatible optimizer): Either a string or a
            torch-compatible optimizer. The only strings currently used are
            &#34;Adam&#34;, &#34;DiffGrad&#34; and &#34;Yogi&#34;.
        verbose (bool, optional): Print out information during the run.
            Defaults to False.
        print_every (int, optional):    If verbose is True, then how frequently
            to print out the information on the run progress. Also controls
            how often the best chi2 value is updated for the progress-bar.
        betas (list, optional): beta1 and beta2 values to use in Adam. Defaults
            to [0.9, 0.9] (if None set) which is equivalent to
            [beta1=0.9, beta2=0.9]
        eps (float, optional): Epsilon value to use in Adam or Adam derived
            optimizers. Defaults to 1e-8.
        loss (str or function, optional):   Pytorch requires a scalar to
            determine the gradients so the series of chi2 values obtained from
            the n_samples must be combined through some function before the
            gradient is determined. Different functions can be used to scaled
            the gradients in different ways. This may be advantageous if there
            is a significant difference in the magnitude of the gradient when
            chi2 is large vs when it is small. If string, must be one of:
            sum, sse, xlogx
                sum     -   add all the chi2 values together. The gradient for
                            each independent run will be the derivative of chi2
                            with respect to the degrees of freedom.
                sse     -   sum(chi2^2) (sum of squared errors). The gradient
                            for each independent run will be the derivative of
                            chi2 (wrt DoF) multiplied by 2*chi2.
                xlogx   -   sum(chi2 * log(chi2)). The gradient for each
                            independent run will be the derivative of chi2 (wrt
                            DoF) multiplied by log(chi2) + 1.
            If a function, this function must must take as input a pytorch
            tensor and return a scalar.
            Defaults to &#34;sum&#34;.
        start_time (time.time(), optional): The start time of a run or set of
            runs. Useful in full GALLOP runs, but if set to None then the start
            time will automatically be determined.
        run (int, optional): If a set of runs are being performed, then the run
            number can be passed for printing. Defaults to 1.
        save_trajectories (bool, optional): Store the DoF, chi_2 and loss value
            after every iteration. This will be slow, as it requires transfer
            from the GPU to CPU. Defaults to False.
        save_grad (bool, optional): Store the gradients of the internal and
            external DoF with respect to the chi_2 / loss values after every
            iteration. This will be slow, as it requires transfer from the GPU
            to CPU. Defaults to False.
        save_loss (bool, optional) : Save the value of the loss at each
            iteration. Used by find_learning_rate. Defaults to False.
        include_dw_factors (bool, optional): Include Debye-Waller factors in
            the intensity calculations. Defaults to True.
        chi2_solved (float, optional):  The value below which a structure is
            considered solved (if known). Used for some printed information.
            If None, then this is ignored. Defaults to None.
        ignore_reflections_for_chi2_calc (bool, optional):  The normal chi2
            calculation divides the output by (n_reflections - 2)
            i.e. chi2 = d.A.d / (n_reflections - 2)
            If set to True, this reverses this operation. Defaults to False.
        use_progress_bar (bool, optional): Use a progress bar to provide visual
            feedback on run progress. Defaults to True.
        save_CIF (bool, optional): Save a CIF of the best structure found
            after optimising. Defaults to True.
        streamlit (bool, optional): If using the streamlit webapp interface,
            this is set to True to enable a progress bar etc. Defaults to False

    Returns:
        dictionary: A dictionary containing the optimised external and internal
            degrees of freedom and their associated chi_2 values.
            If save_trajectories is True then this also contains the
            trajectories of the particles, the chi_2 values and loss values
            at each iteration.
    &#34;&#34;&#34;
    if b_bounds_1_cycle is None:
        b_bounds_1_cycle = {&#34;upperb1&#34;:0.95, &#34;lowb1&#34;:0.85, &#34;upperb2&#34;:0.9,
                            &#34;lowb2&#34;:0.9}
    if betas is None:
        betas = [0.9,0.9]
    if streamlit:
        import streamlit as st

    # Load the tensors and other parameters needed
    tensors = tensor_prep.get_all_required_tensors(
                                Structure, external=external, internal=internal,
                                n_samples=n_samples, device=device, dtype=dtype,
                                n_reflections=n_reflections, verbose=verbose,
                                include_dw_factors=include_dw_factors)
    trajectories = []
    gradients = []
    losses = []

    # Initialize the optimizer
    if isinstance(optimizer, str):
        if learning_rate_schedule.lower() == &#34;array&#34;:
            init_lr = learning_rate[0]
        else:
            init_lr = learning_rate
        if optimizer.lower() == &#34;adam&#34;:
            optimizer = torch.optim.Adam([tensors[&#34;external&#34;],
                                        tensors[&#34;internal&#34;]],
                                        lr=init_lr, betas=betas, eps=eps)
        elif optimizer.lower() == &#34;yogi&#34;:
            optimizer = t_optim.Yogi([tensors[&#34;external&#34;],
                                        tensors[&#34;internal&#34;]],
                                        lr=init_lr, betas=betas, eps=eps)
        elif optimizer.lower() == &#34;diffgrad&#34;:
            optimizer = t_optim.DiffGrad([tensors[&#34;external&#34;],
                                        tensors[&#34;internal&#34;]],
                                        lr=init_lr, betas=betas, eps=eps)
        else:
            print(&#34;Only supported optimizers are \&#34;Adam\&#34;, \&#34;DiffGrad\&#34; or&#34;,
            &#34;\&#34;Yogi\&#34;.&#34;)
            exit()
    else:
        # Ensure that the optimizer is a torch compatible optimizer that
        # accepts learning rate changes
        if not hasattr(optimizer, &#34;param_groups&#34;):
            print(&#34;Optimizer not compatible&#34;)
            exit()
        else:
            optimizer.param_groups[0][&#34;params&#34;] = [tensors[&#34;external&#34;],
                                                    tensors[&#34;internal&#34;]]
            for param_group in optimizer.param_groups:
                if learning_rate_schedule.lower() == &#34;array&#34;:
                    param_group[&#39;lr&#39;] = learning_rate[0]
                else:
                    param_group[&#39;lr&#39;] = learning_rate

    if start_time is None:
        t1 = time.time()
    else:
        t1 = start_time

    # Add the progress bar, if using
    if use_progress_bar and not streamlit:
        iters = tqdm.trange(n_iterations)
    else:
        iters = range(n_iterations)
        if streamlit:
            prog_bar = st.progress(0.0)

    # Now perform the optimisation iterations
    for i in iters:
        # Zero out gradient, else they will accumulate between iterations
        optimizer.zero_grad()

        if learning_rate_schedule.lower() == &#34;1cycle&#34;:
            lr = adjust_lr_1_cycle(optimizer, i, learning_rate/10,
                    learning_rate, n_iterations-n_cooldown, n_iterations,
                    **b_bounds_1_cycle)
        elif learning_rate_schedule.lower() == &#34;sqrt&#34;:
            lr = adjust_lr_1_over_sqrt(optimizer, i, learning_rate)
        elif learning_rate_schedule.lower() == &#34;constant&#34;:
            lr = learning_rate
        elif learning_rate_schedule.lower() == &#34;array&#34;:
            try:
                lr = learning_rate[i]
                for param_group in optimizer.param_groups:
                    param_group[&#39;lr&#39;] = lr
            except IndexError:
                print(&#34;Error in learning rate array&#34;)
                if len(learning_rate) &lt; i:
                    print(&#34;Insufficient entries in list, using last value&#34;)
                    lr = learning_rate[-1]
                else:
                    print(&#34;Check and try again&#34;)
                    exit()
        else:
            if i == 0:
                print(&#34;Learning rate scheduler unknown, using 1cycle&#34;)
                learning_rate_schedule=&#34;1cycle&#34;
                lr = adjust_lr_1_cycle(optimizer, i, learning_rate/10,
                        learning_rate, n_iterations-n_cooldown, n_iterations)
            else:
                print(&#34;An error has occurred with lr scheduling&#34;)

        # Forward pass - this gets a tensor of shape (n_samples, 1) with a
        # chi_2 value for each set of external/internal DoFs.
        chi_2 = chi2.get_chi_2(**tensors)
        if ignore_reflections_for_chi2_calc:
            # Counteract the division normally used in chi2 calculation
            chi_2 *= (tensors[&#34;hkl&#34;].shape[1] - 2)

        # PyTorch expects a single value for backwards pass.
        # Need a function to convert all of the chi_2 values into a scalar
        if isinstance(loss, str):
            if loss.lower() == &#34;sse&#34;:
                L = (chi_2**2).sum()
            elif loss.lower() == &#34;sum&#34;:
                L = chi_2.sum()
            elif loss.lower() == &#34;xlogx&#34;:
                L = torch.sum(chi_2*torch.log(chi_2))
        else:
            if loss is None:
                # Default to the sum operation if loss is None
                L = chi_2.sum()
            else:
                try:
                    L = loss(chi_2)
                except RuntimeError:
                    print(&#34;Unknown / incompatible loss function&#34;,loss)
                    print(&#34;Allowable arguments = sse (sum of squared errors),&#34;,
                        &#34;sum, xlogx or a suitable function that returns a&#34;,
                        &#34;single scalar value&#34;)

        # Backward pass to calculate gradients
        L.backward()
        if save_loss:
            losses.append(L.detach().cpu().numpy())
        if i == 0:
            best = torch.min(chi_2).item()
            best_iteration = 1
        else:
            if i % check_min == 0:
                if torch.min(chi_2).item() &lt; best:
                    best = torch.min(chi_2).item()
                    best_iteration = i
        i+=1
        if verbose:
            if i % print_every == 0 or i == 1:
                detached_chi2 = chi_2.detach().cpu().numpy()
                if chi2_solved is not None:
                    n_solved = detached_chi2[detached_chi2 &lt; chi2_solved]
                    printstring = (
                        &#34;GALLOP iter {:04d} | LO iter {:04d} | lr {:.3f} ||&#34;,
                        &#34;max/mean/min chi^2 {:.1f} / {:.1f} / {:.1f} ||&#34;,
                        &#34;Time {:.1f} (s) / {:.1f} (min) || Best {:.1f}&#34;,
                        &#34;in iter {:04d} || n&lt;{:.1f}: {:05d}&#34;)
                    print(&#34;&#34;.join(printstring).format(
                            run+1, i, lr,
                            chi_2.max().item(), chi_2.mean().item(),
                            chi_2.min().item(), time.time() - t1,
                            (time.time() - t1)/60, best, best_iteration,
                            chi2_solved, n_solved.shape[0]))
                else:
                    printstring = (
                        &#34;GALLOP iter {:04d} | LO iter {:04d} | lr {:.3f} ||&#34;,
                        &#34;max/mean/min chi^2 {:.1f} / {:.1f} / {:.1f} ||&#34;,
                        &#34;Time {:.1f} (s) / {:.1f} (min) || Best {:.1f}&#34;
                        &#34;in iter {:04d}&#34;)
                    print(&#34;&#34;.join(printstring).format(
                            run+1, i, lr,
                            chi_2.max().item(), chi_2.mean().item(),
                            chi_2.min().item(), time.time() - t1,
                            (time.time() - t1)/60, best,
                            best_iteration))
        elif use_progress_bar and not streamlit:
            if i % print_every == 0 or i == 1:
                iters.set_description(
                    &#34;GALLOP iter {:04d} LO iter {:04d} min chi2 {:.1f}&#34;.format(
                        run+1, i, chi_2.min().item()))
        if save_trajectories:
            trajectories.append([tensors[&#34;external&#34;].detach().cpu().numpy(),
                                tensors[&#34;internal&#34;].detach().cpu().numpy(),
                                chi_2.detach().cpu().numpy(),
                                L.detach().cpu().numpy()])
        if save_grad:
            gradients.append([tensors[&#34;external&#34;].grad.detach().cpu().numpy(),
                            tensors[&#34;internal&#34;].grad.detach().cpu().numpy()])
        if i != n_iterations:
            optimizer.step()
        if streamlit:
            prog_bar.progress(i/n_iterations)
    result = {
            &#34;external&#34;     : tensors[&#34;external&#34;].detach().cpu().numpy(),
            &#34;internal&#34;     : tensors[&#34;internal&#34;].detach().cpu().numpy(),
            &#34;chi_2&#34;        : chi_2.detach().cpu().numpy(),
            &#34;GALLOP Iter&#34;  : run
            }
    if save_CIF:
        files.save_CIF_of_best_result(Structure, result, start_time,
                                        n_reflections)
    if save_trajectories:
        result[&#34;trajectories&#34;] = trajectories
    if save_loss:
        result[&#34;losses&#34;] = np.array(losses)
    if save_grad:
        result[&#34;gradients&#34;] = gradients
    del tensors

    return result</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.plot_torsion_difference"><code class="name flex">
<span>def <span class="ident">plot_torsion_difference</span></span>(<span>Structure, result, n_swarms=1, verbose=False, figsize=(10, 10), xlim=None, ylim=None, cmap='tab20', call_show=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the average difference between the known torsions (obtained
from the Z-matrix input) to those obtained in an SDPD attempt.</p>
<p>Torsion angles are first cast into the plane in order to account for the
fact that 0 deg == 360 deg.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Structure</code></strong> :&ensp;<code>class</code></dt>
<dd>Structure object containing the true torsions,
read in from the Z-matrices.</dd>
<dt><strong><code>result</code></strong> :&ensp;<code>dict</code></dt>
<dd>A result dict returned by the minimise function, which
contains the internal DoF and the chi_2 values.</dd>
<dt><strong><code>n_swarms</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>plot the separate swarms in different colours
or set to 1 to plot all with the same colour. Defaults to 1.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print out information. Defaults to False.</dd>
<dt><strong><code>figsize</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>Size of the plot. Defaults to (10,10).</dd>
<dt><strong><code>xlim</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Limits of the x-axis.
Defaults to {"left" : 0, "right" : None}.</dd>
<dt><strong><code>ylim</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Limits of the y-axis.
Defaults to {"bottom" : 0, "top" : None}.</dd>
<dt><strong><code>cmap</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>the matplotlib colourmap to use.
Defaults to tab20</dd>
<dt><strong><code>call_show</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, will call plt.show() to render the
plot. If False, the plot can be used in a subplot along with other
plots by the user in the parent script or notebook.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_torsion_difference(Structure, result, n_swarms=1,
    verbose=False, figsize=(10,10), xlim=None,
    ylim=None, cmap=&#34;tab20&#34;, call_show=True):
    &#34;&#34;&#34;
    Calculate the average difference between the known torsions (obtained
    from the Z-matrix input) to those obtained in an SDPD attempt.

    Torsion angles are first cast into the plane in order to account for the
    fact that 0 deg == 360 deg.

    Args:
        Structure (class): Structure object containing the true torsions,
            read in from the Z-matrices.
        result (dict): A result dict returned by the minimise function, which
            contains the internal DoF and the chi_2 values.
        n_swarms (int, optional): plot the separate swarms in different colours
            or set to 1 to plot all with the same colour. Defaults to 1.
        verbose (bool, optional): Print out information. Defaults to False.
        figsize (tuple, optional): Size of the plot. Defaults to (10,10).
        xlim (dict, optional): Limits of the x-axis.
            Defaults to {&#34;left&#34; : 0, &#34;right&#34; : None}.
        ylim (dict, optional): Limits of the y-axis.
            Defaults to {&#34;bottom&#34; : 0, &#34;top&#34; : None}.
        cmap (str, optional): the matplotlib colourmap to use.
            Defaults to tab20
        call_show (bool, optional): If True, will call plt.show() to render the
            plot. If False, the plot can be used in a subplot along with other
            plots by the user in the parent script or notebook.
    &#34;&#34;&#34;
    if xlim is None:
        xlim = {&#34;left&#34; : 0, &#34;right&#34; : None}
    if ylim is None:
        ylim = {&#34;bottom&#34; : 0, &#34;top&#34; : None}
    true_torsions = Structure.zm_torsions
    internal = result[&#34;internal&#34;]
    chi_2 = result[&#34;chi_2&#34;]
    subswarm = internal.shape[0] // n_swarms
    diff = true_torsions - internal
    sindiff = np.sin(diff)
    cosdiff = np.cos(diff)

    if verbose:
        if chi_2 is not None:
            mean_ang_diff = np.arctan2(sindiff.mean(axis=1),
                                        cosdiff.mean(axis=1))
            mean_ang_diff = (180/np.pi)*(mean_ang_diff)
            print(&#34;Mean diff, min mean diff, chi2 min mean diff&#34;)
            print(np.abs(mean_ang_diff).mean(), np.abs(mean_ang_diff).min(),
                                            mean_ang_diff[chi_2 == chi_2.min()])

    c_coord_diff = np.cos(true_torsions) - np.cos(internal)
    s_coord_diff = np.sin(true_torsions) - np.sin(internal)
    dist = np.sqrt((c_coord_diff**2 + s_coord_diff**2).mean(axis=1))
    if call_show:
        plt.figure(figsize=figsize)
    plt.scatter(chi_2, dist, s=10, cmap=cmap, alpha=0.75,
                    c=(np.arange(internal.shape[0])//subswarm))
    plt.xlim(**xlim)
    plt.ylim(**ylim)
    if call_show:
        plt.show()</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.seed_everything"><code class="name flex">
<span>def <span class="ident">seed_everything</span></span>(<span>seed=1234, change_backend=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Set random seeds for everything.
Note that at the moment, CUDA (which is used by PyTorch) is not
deterministic for some operations and as a result, GALLOP runs from
the same seed may still produce different result.
See here for more details:
<a href="https://pytorch.org/docs/stable/notes/randomness.html">https://pytorch.org/docs/stable/notes/randomness.html</a></p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Set the random seed to be used.
Defaults to 1234.</dd>
<dt><strong><code>change_backend</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to change the backend used to
try to make the code more reproducible. At the moment, it doesn't
seem to help&hellip; default to False</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def seed_everything(seed=1234, change_backend=False):
    &#34;&#34;&#34;
    Set random seeds for everything.
    Note that at the moment, CUDA (which is used by PyTorch) is not
    deterministic for some operations and as a result, GALLOP runs from
    the same seed may still produce different result.
    See here for more details:
        https://pytorch.org/docs/stable/notes/randomness.html

    Args:
        seed (int, optional): Set the random seed to be used.
            Defaults to 1234.
        change_backend (bool, optional): Whether to change the backend used to
            try to make the code more reproducible. At the moment, it doesn&#39;t
            seem to help... default to False
    &#34;&#34;&#34;
    random.seed(seed)
    os.environ[&#39;PYTHONHASHSEED&#39;] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    if change_backend:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="gallop.optimiser.Swarm"><code class="flex name class">
<span>class <span class="ident">Swarm</span></span>
<span>(</span><span>Structure, n_particles=10000, n_swarms=10, particle_best_position=None, best_chi_2=None, velocity=None, position=None, best_subswarm_chi_2=None, inertia='ranked', c1=1.5, c2=1.5, inertia_bounds=(0.4, 0.9), use_matrix=True, limit_velocity=True, global_update=False, global_update_freq=10, vmax=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for the particle swarm optimiser used in GALLOP.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Structure</code></strong> :&ensp;<code>class</code></dt>
<dd>GALLOP structure object</dd>
<dt><strong><code>n_particles</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of particles to optimise.
Defaults to 10000.</dd>
<dt><strong><code>n_swarms</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of independent swarms which
are represented by the n_particles. Defaults to 20.</dd>
<dt><strong><code>particle_best_position</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>the best position
on the hypersurface obtained by each particle. Defaults to None.</dd>
<dt><strong><code>best_chi_2</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>The best chi_2 obtained by each
particle. Defaults to None.</dd>
<dt><strong><code>velocity</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>The current velocity of the
particles. Defaults to None.</dd>
<dt><strong><code>position</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>The current position of the
particles. Defaults to None.</dd>
<dt><strong><code>best_subswarm_chi_2</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The best chi_2 found in each
subswarm. Defaults to None.</dd>
<dt><strong><code>inertia</code></strong> :&ensp;<code>float</code> or <code>str</code>, optional</dt>
<dd>The inertia to use in the velocity
update. If random, sample the inertia from a uniform
distribution. If "ranked", then solutions ranked in order of
increasing chi2. Lowest chi2 assigned lowest inertia, as defined
by bounds in inertia_bounds. Defaults to "ranked".</dd>
<dt><strong><code>c1</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>c1 (social) parameter in PSO equation.
Defaults to 1.5</dd>
<dt><strong><code>c2</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>c2 (cognitive) parameter in PSO equation.
Defaults to 1.5</dd>
<dt><strong><code>inertia_bounds</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>The upper and lower bound of the
values that inertia will take if inertia is set to "random" or
"ranked".
Defaults to [0.4,0.9].</dd>
<dt><strong><code>use_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Take a different step size in every
degree of freedom. Defaults to True.</dd>
<dt><strong><code>limit_velocity</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Restrict the velocity to the range
(-vmax, vmax). Defaults to True.</dd>
<dt><strong><code>global_update</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, allow global updates (see
below). Defaults to False.</dd>
<dt><strong><code>global_update_freq</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If using subswarms, it may be
desirable to occasionally update all subswarms swarm as a single
swarm to allow communication of information from different
regions of the hypersurface. Setting this to an integer will
activate the global update when:
run number % global_update_freq == 0 and run number &gt; 0
Defaults to 10.</dd>
<dt><strong><code>vmax</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The absolute maximum velocity a particle can
achieve if limit_velocity is True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Swarm(object):
    def __init__(self, Structure, n_particles=10000, n_swarms=10,
        particle_best_position = None, best_chi_2 = None, velocity = None,
        position = None, best_subswarm_chi_2 = None, inertia=&#34;ranked&#34;, c1=1.5,
        c2=1.5, inertia_bounds=(0.4,0.9), use_matrix=True, limit_velocity=True,
        global_update=False, global_update_freq=10, vmax=1):
        &#34;&#34;&#34;
        Class for the particle swarm optimiser used in GALLOP.

        Args:
            Structure (class): GALLOP structure object
            n_particles (int, optional): The number of particles to optimise.
                Defaults to 10000.
            n_swarms (int, optional): The number of independent swarms which
                are represented by the n_particles. Defaults to 20.
            particle_best_position (numpy array, optional): the best position
                on the hypersurface obtained by each particle. Defaults to None.
            best_chi_2 (numpy array, optional): The best chi_2 obtained by each
                particle. Defaults to None.
            velocity (numpy array, optional): The current velocity of the
                particles. Defaults to None.
            position (numpy array, optional): The current position of the
                particles. Defaults to None.
            best_subswarm_chi_2 (list, optional): The best chi_2 found in each
                subswarm. Defaults to None.
            inertia (float or str, optional): The inertia to use in the velocity
                update. If random, sample the inertia from a uniform
                distribution. If &#34;ranked&#34;, then solutions ranked in order of
                increasing chi2. Lowest chi2 assigned lowest inertia, as defined
                by bounds in inertia_bounds. Defaults to &#34;ranked&#34;.
            c1 (int, optional): c1 (social) parameter in PSO equation.
                Defaults to 1.5
            c2 (int, optional): c2 (cognitive) parameter in PSO equation.
                Defaults to 1.5
            inertia_bounds (list, optional): The upper and lower bound of the
                values that inertia will take if inertia is set to &#34;random&#34; or
                &#34;ranked&#34;.
                Defaults to [0.4,0.9].
            use_matrix (bool, optional): Take a different step size in every
                degree of freedom. Defaults to True.
            limit_velocity (bool, optional): Restrict the velocity to the range
                (-vmax, vmax). Defaults to True.
            global_update (bool, optional): If True, allow global updates (see
                below). Defaults to False.
            global_update_freq (int, optional): If using subswarms, it may be
                desirable to occasionally update all subswarms swarm as a single
                swarm to allow communication of information from different
                regions of the hypersurface. Setting this to an integer will
                activate the global update when:
                    run number % global_update_freq == 0 and run number &gt; 0
                Defaults to 10.
            vmax (float, optional): The absolute maximum velocity a particle can
                achieve if limit_velocity is True.
        &#34;&#34;&#34;
        self.Structure = Structure
        self.particle_best_position = particle_best_position
        self.best_chi_2 = best_chi_2
        self.velocity = velocity
        self.position = position
        self.n_swarms = n_swarms
        self.best_subswarm_chi_2 = best_subswarm_chi_2
        self.inertia = inertia
        self.c1 = c1
        self.c2 = c2
        self.inertia_bounds = inertia_bounds
        self.use_matrix = use_matrix
        self.swarm_progress = []
        self.limit_velocity = limit_velocity
        self.n_particles = n_particles
        self.best_low_res_chi_2 = None
        self.best_high_res_chi_2 = None
        self.global_update = global_update
        self.global_update_freq = global_update_freq
        self.vmax = vmax
        self.best_subswarm_chi2 = []

    def get_initial_positions(self, method=&#34;latin&#34;, latin_criterion=None):
        &#34;&#34;&#34;
        Generate the initial starting points for a GALLOP attempt. The
        recommended method uses latin hypercube sampling which provides a
        more even coverage of the search space than random uniform sampling,
        which can produce clusters or leave regions unexplored.

        Args:
            method (str, optional): The sampling method to use. Can be one of
                &#34;latin&#34; or &#34;uniform&#34;. Defaults to &#34;latin&#34;.
            latin_criterion (str, optional): The criterion to be used with the
                latin hypercube method. See pyDOE documentation here:
                https://pythonhosted.org/pyDOE/randomized.html#latin-hypercube
                Defaults to None.

        Returns:
            tuple: Tuple of numpy arrays containing the initial external and
            internal degrees of freedom
        &#34;&#34;&#34;
        if self.Structure.total_internal_degrees_of_freedom is None:
            self.Structure.get_total_degrees_of_freedom()

        assert method in [&#34;uniform&#34;, &#34;latin&#34;], &#34;method must be latin or uniform&#34;
        if self.n_particles % self.n_swarms != 0:
            print(&#34;n_particles should be divisible by n_swarms.&#34;)
            self.n_particles = self.n_swarms * (self.n_particles//self.n_swarms)
            print(&#34;Setting n_particles to&#34;, self.n_particles)
        subswarm = self.n_particles // self.n_swarms
        init_external = []
        init_internal = []

        total_pos = self.Structure.total_position_degrees_of_freedom
        total_rot = self.Structure.total_rotation_degrees_of_freedom
        tot_external = total_pos+total_rot
        total_tors = self.Structure.total_internal_degrees_of_freedom
        # Separate hypercube for each subswarm
        for _ in tqdm.tqdm(range(self.n_swarms)):
            if method == &#34;latin&#34;:
                all_dof = np.array(pyDOE.lhs(total_pos + total_rot + total_tors,
                            samples=subswarm, criterion=latin_criterion))
                external = all_dof[:,:total_pos+total_rot]
                pos = external[:,:total_pos]
                rot = external[:,total_pos:]
                tor = all_dof[:,total_pos+total_rot:]
                rot -= 0.5
                rot *= 2. # Rotation to range [-1,1]
                tor -= 0.5
                tor *= 2. * np.pi # Torsions to range [-pi,pi]
                init_external.append(np.hstack([pos,rot]))
                init_internal.append(tor)

            else:
                rand_ext = np.random.uniform(-1,1,size=(subswarm,tot_external))
                rand_int = np.random.uniform(-1,1,size=(subswarm,total_tors))
                init_external.append(rand_ext)
                init_internal.append(rand_int)

        init_external = np.vstack(init_external)
        init_internal = np.vstack(init_internal)
        return init_external, init_internal


    def update_best(self, chi_2):
        &#34;&#34;&#34;
        Update the swarm with the best position and chi_2 for each particle

        Args:
            chi_2 (numpy array): the most recently obtained chi_2 values
        &#34;&#34;&#34;
        better = chi_2 &lt; self.best_chi_2
        self.particle_best_position[better] = self.position[better]
        self.best_chi_2[better] = chi_2[better]

    def get_position_from_dof(self, external, internal):
        &#34;&#34;&#34;
        Particle position values are unbounded, which can cause some issues
        with the swarm updates. This can be remedied in part by normalising
        all of the coordinates into the range -1 to +1.
        It also means that all of the coordinates will have the same range in
        the swarm, allowing easy comparison of exploration directions.

        For torsions, this is simple - merely take sin and cosine of the angles.
        For quaternions, ensuring that they are unit quaternions should do the
        trick.
        For the translations, this function uses the following:
            2 * ((translation % 1) - 0.5)

        Args:
            Structure (class): GALLOP structure which holds information about
                which indices of external and internal correspond to
                translations and rotations
            external (numpy array): External degrees of freedom
            internal (numpy array): Internal degrees of freedom

        Returns:
            numpy array : The normalised and stacked positions of the particles.
                Order is translation, rotation, torsion
        &#34;&#34;&#34;
        end_of_translations = self.Structure.total_position_degrees_of_freedom
        n_quaternions = self.Structure.total_rotation_degrees_of_freedom // 4
        translation = np.copy(external[:,:end_of_translations])
        translation = translation % 1    # Convert into range(0,1)
        translation *= 2 * np.pi         # Convert into range(0, 2pi)
        translation = np.hstack([np.sin(translation), np.cos(translation)])

        rotation = np.copy(external[:,end_of_translations:])
        rotation_list = []
        for i in range(n_quaternions):
            # Ensure quaternions are unit quaternions
            quaternion = rotation[:,(i*4):(i+1)*4]
            quaternion /= np.sqrt((quaternion**2).sum(axis=1)).reshape(-1,1)
            rotation_list.append(quaternion)
        rotation = np.hstack(rotation_list)
        # Take the sin and cos of the torsions, and stack everything.
        # Range for all parameters is now -1 to +1
        position = np.hstack([translation, rotation,
                                np.sin(internal), np.cos(internal)])

        return position


    def get_new_external_internal(self, position):
        &#34;&#34;&#34;
        Convert the swarm representation of position back to the external
        and internal degrees of freedom expected by GALLOP

        Args:
            position (numpy array): The internal swarm representation of the
                particle positions, where the positions and torsion angles have
                been projected onto the unit circle.

        Returns:
            tuple: Tuple of numpy arrays containing the external and internal
                degrees of freedom
        &#34;&#34;&#34;
        total_position = self.Structure.total_position_degrees_of_freedom
        total_rotation = self.Structure.total_rotation_degrees_of_freedom
        total_torsional = self.Structure.total_internal_degrees_of_freedom
        n_quaternions = total_rotation // 4
        end_external = (2*total_position) + total_rotation
        external = np.copy(position[:,:end_external])
        internal = np.copy(position[:,end_external:])
        # Reverse the normalisation of the particle position,
        # back to range 0 - 1
        pos_sines = external[:,:total_position]
        pos_cosines = external[:,total_position:2*total_position]
        # Can now use the inverse tangent to get positions in range -0.5, 0.5
        translations = np.arctan2(pos_sines, pos_cosines) / (2*np.pi)

        rotations = external[:,2*total_position:]
        rotation_list = []
        for i in range(n_quaternions):
            # Ensure the quaternions are unit quaternions
            quaternion = rotations[:,(i*4):(i+1)*4]
            quaternion /= np.sqrt((quaternion**2).sum(axis=1)).reshape(-1,1)
            rotation_list.append(quaternion)
        rotations = np.hstack(rotation_list)

        external = np.hstack([translations, rotations])
        # Revert torsion representation back to angles using the inverse tangent
        internal = np.arctan2(internal[:,:total_torsional],
                            internal[:,total_torsional:])

        return external, internal

    def PSO_velocity_update(self, previous_velocity, position,
        particle_best_pos, best_chi_2, inertia=&#34;random&#34;, c1=1.5, c2=1.5,
        inertia_bounds=(0.4,0.9), use_matrix=True):
        &#34;&#34;&#34;
        Update the velocity of the particles in the swarm

        Args:
            previous_velocity (numpy array): Current velocity
            position (numpy array): Current position
            particle_best_pos (numpy array): Best position for each particle
            best_chi_2 (numpy array): Best chi_2 for each particle
            inertia (str, numpy array or float, optional): Inertia to use.
                If string, can currently only be &#34;random&#34; or &#34;ranked&#34;.
                If random, then the inertia is randomly set for each particle
                within the bounds supplied in the parameter inertia_bounds.
                If &#34;ranked&#34;, then set the inertia values linearly between the
                bounds, with the lowest inertia for the best particle. If a
                float, then all particles are assigned the same inertia.
                Defaults to &#34;random&#34;.
            c1 (int, optional): c1 (social) parameter in PSO equation.
                Defaults to 1.5.
            c2 (int, optional): c2 (cognitive) parameter in PSO equation.
                Defaults to 1.5.
            inertia_bounds (tuple, optional): The upper and lower bound of the
                values that inertia can take if inertia is set to &#34;random&#34; or
                &#34;ranked&#34;. Defaults to (0.4,0.9)
            use_matrix (bool, optional): Take a different step size in every
                degree of freedom. Defaults to True.

        Returns:
            numpy array: The updated velocity of each particle
        &#34;&#34;&#34;
        global_best_pos = particle_best_pos[best_chi_2 == best_chi_2.min()]
        if global_best_pos.shape[0] &gt; 1:
            global_best_pos = global_best_pos[0]
        if (not isinstance(inertia, float)
                                    and not isinstance(inertia, np.ndarray)):
            if inertia.lower() == &#34;random&#34;:
                inertia = np.random.uniform(inertia_bounds[0],
                                        inertia_bounds[1],
                                        size=(previous_velocity.shape[0], 1))
            elif inertia.lower() == &#34;ranked&#34;:
                ranks = np.argsort(best_chi_2) + 1
                inertia = inertia_bounds[0] + (ranks * (inertia_bounds[1]
                                        - inertia_bounds[0]))/ranks.shape[0]
                inertia = inertia.reshape(-1,1)
            elif inertia.lower() == &#34;r_ranked&#34;:
                ranks = np.argsort(1/best_chi_2) + 1
                inertia = inertia_bounds[0] + (ranks * (inertia_bounds[1]
                                        - inertia_bounds[0]))/ranks.shape[0]
                inertia = inertia.reshape(-1,1)
            else:
                print(&#34;Unknown inertia type!&#34;, inertia)
                print(&#34;Setting inertia to 0.5&#34;)
                inertia = 0.5
        if use_matrix:
            R1 = np.random.uniform(0,1,size=(position.shape[0],
                                            position.shape[1]))
            R2 = np.random.uniform(0,1,size=(position.shape[0],
                                            position.shape[1]))
        else:
            R1 = np.random.uniform(0,1,size=(position.shape[0], 1))
            R2 = np.random.uniform(0,1,size=(position.shape[0], 1))

        new_velocity = (inertia*previous_velocity
                        + c1*R1*(global_best_pos - position)
                        + c2*R2*(particle_best_pos - position))

        return new_velocity

    def get_new_velocities(self, global_update=True, verbose=True):
        &#34;&#34;&#34;
        Update the particle velocities using the PSO equations.
        Can either update all particles as a single swarm, or treat them as a
        set of independent swarms (or subswarms).

        Args:
            global_update (bool, optional): If True, update all of the particles
                as a single swarm. If False, then update n_swarms separately.
                Defaults to True.
            verbose (bool, optional): Print out if a global update is being
                performed. Defaults to True.
        &#34;&#34;&#34;
        subswarm = self.n_particles // self.n_swarms
        use_ranked_all = False
        if isinstance(self.inertia, str):
            if self.inertia.lower() == &#34;ranked_all&#34;:
                ranks = np.argsort(self.best_chi_2) + 1
                ranked_inertia = (self.inertia_bounds[0]
                            + (ranks * (self.inertia_bounds[1]
                            - self.inertia_bounds[0]))/ranks.shape[0])
                ranked_inertia = ranked_inertia.reshape(-1,1)
                use_ranked_all = True
        if global_update:
            if verbose:
                print(&#34;Global&#34;)
            if use_ranked_all:
                self.velocity = self.PSO_velocity_update(self.velocity,
                                    self.position, self.particle_best_position,
                                    self.best_chi_2, inertia=ranked_inertia,
                                    c1=self.c1, c2=self.c2,
                                    inertia_bounds=self.inertia_bounds,
                                    use_matrix=self.use_matrix)
            else:
                self.velocity = self.PSO_velocity_update(self.velocity,
                                    self.position, self.particle_best_position,
                                    self.best_chi_2, inertia=self.inertia,
                                    c1=self.c1, c2=self.c2,
                                    inertia_bounds=self.inertia_bounds,
                                    use_matrix=self.use_matrix)
            for j in range(self.n_swarms):
                begin = j*subswarm
                end = (j+1)*subswarm
                self.best_subswarm_chi2.append(self.best_chi_2[begin:end].min())
            self.swarm_progress.append(self.best_subswarm_chi2)
        else:
            for j in range(self.n_swarms):
                begin = j*subswarm
                end = (j+1)*subswarm
                swarm_v = self.velocity[begin:end]
                swarm_pos = self.position[begin:end]
                swarm_best_pos = self.particle_best_position[begin:end]
                swarm_chi2 = self.best_chi_2[begin:end]
                if use_ranked_all:
                    swarm_ranked_inertia = ranked_inertia[begin:end]
                    new_vel = self.PSO_velocity_update(swarm_v, swarm_pos,
                            swarm_best_pos, swarm_chi2,
                            inertia=swarm_ranked_inertia,
                            c1=self.c1, c2=self.c2,
                            inertia_bounds=self.inertia_bounds,
                            use_matrix=self.use_matrix)
                else:
                    new_vel = self.PSO_velocity_update(swarm_v, swarm_pos,
                            swarm_best_pos, swarm_chi2, inertia=self.inertia,
                            c1=self.c1, c2=self.c2,
                            inertia_bounds=self.inertia_bounds,
                            use_matrix=self.use_matrix)
                self.velocity[begin:end] = new_vel
                self.best_subswarm_chi2.append(swarm_chi2.min())
            self.swarm_progress.append(self.best_subswarm_chi2)

        if self.limit_velocity:
            unlimited = self.velocity
            self.velocity[unlimited &gt; self.vmax] = self.vmax
            self.velocity[unlimited &lt; -1*self.vmax] = -1*self.vmax

    def update_position(self, result=None, external=None, internal=None,
        chi_2=None, run=None, global_update=False, verbose=True, n_swarms=None):
        &#34;&#34;&#34;
        Take a set of results from the minimisation algorithm and use
        them to generate a new set of starting points to be minimised. This
        will also update the internal swarm representation of position and
        velocity.

        Args:
            result (dict, optional): The result dict from a GALLOP minimise run.
                Defaults to None.
            external (numpy array, optional): If no result dict is supplied,
                then pass a numpy array of the external DoF. Defaults to None.
            internal (numpy array, optional): If no result dict is supplied,
                then pass a numpy array of the internal DoF. Defaults to None.
            chi_2 (numpy array, optional): If no result dict is supplied,
                then pass a numpy array of the chi_2 values. Defaults to None.
            run (int, optional): If no result dict is supplied, then pass the
                run number. Defaults to None.
            global_update (bool, optional): If True, update all of the particles
                as a single swarm. Defaults to False.
            verbose (bool, optional): Print out information. Defaults to True.
            n_swarms (int, optional): If global_update is False, it use the
                Swarm.n_swarms parameter. This value can be overwritten if
                desired by supplying it as an argument. This could be useful for
                strategies that enable small subswarms to communicate, e.g.
                initially have 2^n swarms, then after some iterations, change to
                2^(n-1) swarms for 1 or more iterations. This would propagate
                information between swarms without doing a full global update.
                Defaults to None.

        Returns:
            tuple: Tuple of numpy arrays containing the external and internal
                degrees of freedom
        &#34;&#34;&#34;
        if result is not None:
            external = result[&#34;external&#34;]
            internal = result[&#34;internal&#34;]
            chi_2 = result[&#34;chi_2&#34;]
            run = result[&#34;GALLOP Iter&#34;]
        else:
            if external is None and internal is None:
                print(&#34;No DoFs supplied!&#34;)
                exit()
        self.position = self.get_position_from_dof(external, internal)
        if self.n_particles is None:
            self.n_particles = external.shape[0]

        if n_swarms is not None:
            self.n_swarms = n_swarms

        if self.particle_best_position is None:
            self.particle_best_position = np.copy(self.position)
            self.best_chi_2 = np.copy(chi_2)
        if self.velocity is None:
            self.velocity = np.zeros_like(self.position)
        self.update_best(chi_2)

        if not global_update:
            if self.global_update_freq is not None and self.global_update:
                if (run+1) % self.global_update_freq == 0 and run != 0:
                    global_update = True
        self.get_new_velocities(global_update=global_update, verbose=verbose)
        self.position = self.position + self.velocity

        if verbose:
            print(self.velocity.min(), self.velocity.max(),
            self.velocity.mean(),
            self.velocity.std(), np.abs(self.velocity).mean(),
            np.abs(self.velocity).std())

        external, internal = self.get_new_external_internal(self.position)

        return external, internal

    def get_CIF_of_best(self, n_reflections=None, one_for_each_subswarm=True,
                                filename_root=None, run=None, start_time=None):
        &#34;&#34;&#34;
        Get a CIF of the best results found by the particle swarm

        Args:
            n_reflections (int, optional): The number of reflections used in the
                SDPD attempts. May be useful if comparing resolutions, but not
                normally needed. If None, then n_reflections = all reflections.
                Defaults to None.
            one_for_each_subswarm (bool, optional): A separate CIF for every
                independent subswarm rather than just the best globally.
                Defaults to True.
            filename_root (str, optional): Specify the root filename to use.
                If None, then use the structure name as the root.
                Defaults to None.
            run (int, optional): The GALLOP iteration. Defaults to None.
            start_time (float, optional): A float produced by time.time() that
                indicates when the run started. Defaults to None.
        &#34;&#34;&#34;
        if not one_for_each_subswarm:
            external, internal = self.get_new_external_internal(
                                                    self.particle_best_position)
            chi_2 = self.best_chi_2
            external = external[chi_2 == chi_2.min()]
            internal = internal[chi_2 == chi_2.min()]
            if external.shape[0] &gt; 1:
                external = external[0]
                internal = internal[0]
            chi_2 = chi_2.min()
            external = external.reshape(1,-1)
            internal = internal.reshape(1,-1)
        else:
            positions, chi2s = [], []
            for i in range(self.n_swarms):
                subswarm = self.n_particles // self.n_swarms
                begin = i*subswarm
                end = (i+1)*subswarm
                swarm_best_pos = self.particle_best_position[begin:end]
                swarm_chi2 = self.best_chi_2[begin:end]
                best_pos = swarm_best_pos[swarm_chi2 == swarm_chi2.min()]
                # If more than one particle has the same chi2, only save one
                # of them.
                if best_pos.shape[0] &gt; 1:
                    best_pos = best_pos[0].reshape(1,-1)
                best_chi_2 = swarm_chi2.min()
                positions.append(best_pos)
                chi2s.append(best_chi_2)
            positions = np.vstack(positions)
            chi2s = np.array(chi2s)
            external, internal = self.get_new_external_internal(positions)
        if filename_root is None:
            filename_root = self.Structure.name
        for i in range(external.shape[0]):
            result = {}
            result[&#34;external&#34;] = external[i]
            result[&#34;internal&#34;] = internal[i]
            result[&#34;chi_2&#34;] = chi2s[i]
            if run is None:
                result[&#34;GALLOP Iter&#34;] = len(self.swarm_progress)
            else:
                result[&#34;GALLOP Iter&#34;] = run
            if start_time is None:
                start_time = time.time()
            files.save_CIF_of_best_result(self.Structure, result, start_time,
                                    n_reflections, filename_root=filename_root
                                    +&#34;_swarm_&#34;+str(i))

    def reset_position_and_velocity(self):
        &#34;&#34;&#34;
        Reset the Particle swarm
        &#34;&#34;&#34;
        self.particle_best_position = None
        self.n_particles = None
        self.velocity = None</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="gallop.optimiser.Swarm.PSO_velocity_update"><code class="name flex">
<span>def <span class="ident">PSO_velocity_update</span></span>(<span>self, previous_velocity, position, particle_best_pos, best_chi_2, inertia='random', c1=1.5, c2=1.5, inertia_bounds=(0.4, 0.9), use_matrix=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the velocity of the particles in the swarm</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>previous_velocity</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Current velocity</dd>
<dt><strong><code>position</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Current position</dd>
<dt><strong><code>particle_best_pos</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Best position for each particle</dd>
<dt><strong><code>best_chi_2</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Best chi_2 for each particle</dd>
<dt><strong><code>inertia</code></strong> :&ensp;<code>str, numpy array</code> or <code>float</code>, optional</dt>
<dd>Inertia to use.
If string, can currently only be "random" or "ranked".
If random, then the inertia is randomly set for each particle
within the bounds supplied in the parameter inertia_bounds.
If "ranked", then set the inertia values linearly between the
bounds, with the lowest inertia for the best particle. If a
float, then all particles are assigned the same inertia.
Defaults to "random".</dd>
<dt><strong><code>c1</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>c1 (social) parameter in PSO equation.
Defaults to 1.5.</dd>
<dt><strong><code>c2</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>c2 (cognitive) parameter in PSO equation.
Defaults to 1.5.</dd>
<dt><strong><code>inertia_bounds</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>The upper and lower bound of the
values that inertia can take if inertia is set to "random" or
"ranked". Defaults to (0.4,0.9)</dd>
<dt><strong><code>use_matrix</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Take a different step size in every
degree of freedom. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy array</code></dt>
<dd>The updated velocity of each particle</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def PSO_velocity_update(self, previous_velocity, position,
    particle_best_pos, best_chi_2, inertia=&#34;random&#34;, c1=1.5, c2=1.5,
    inertia_bounds=(0.4,0.9), use_matrix=True):
    &#34;&#34;&#34;
    Update the velocity of the particles in the swarm

    Args:
        previous_velocity (numpy array): Current velocity
        position (numpy array): Current position
        particle_best_pos (numpy array): Best position for each particle
        best_chi_2 (numpy array): Best chi_2 for each particle
        inertia (str, numpy array or float, optional): Inertia to use.
            If string, can currently only be &#34;random&#34; or &#34;ranked&#34;.
            If random, then the inertia is randomly set for each particle
            within the bounds supplied in the parameter inertia_bounds.
            If &#34;ranked&#34;, then set the inertia values linearly between the
            bounds, with the lowest inertia for the best particle. If a
            float, then all particles are assigned the same inertia.
            Defaults to &#34;random&#34;.
        c1 (int, optional): c1 (social) parameter in PSO equation.
            Defaults to 1.5.
        c2 (int, optional): c2 (cognitive) parameter in PSO equation.
            Defaults to 1.5.
        inertia_bounds (tuple, optional): The upper and lower bound of the
            values that inertia can take if inertia is set to &#34;random&#34; or
            &#34;ranked&#34;. Defaults to (0.4,0.9)
        use_matrix (bool, optional): Take a different step size in every
            degree of freedom. Defaults to True.

    Returns:
        numpy array: The updated velocity of each particle
    &#34;&#34;&#34;
    global_best_pos = particle_best_pos[best_chi_2 == best_chi_2.min()]
    if global_best_pos.shape[0] &gt; 1:
        global_best_pos = global_best_pos[0]
    if (not isinstance(inertia, float)
                                and not isinstance(inertia, np.ndarray)):
        if inertia.lower() == &#34;random&#34;:
            inertia = np.random.uniform(inertia_bounds[0],
                                    inertia_bounds[1],
                                    size=(previous_velocity.shape[0], 1))
        elif inertia.lower() == &#34;ranked&#34;:
            ranks = np.argsort(best_chi_2) + 1
            inertia = inertia_bounds[0] + (ranks * (inertia_bounds[1]
                                    - inertia_bounds[0]))/ranks.shape[0]
            inertia = inertia.reshape(-1,1)
        elif inertia.lower() == &#34;r_ranked&#34;:
            ranks = np.argsort(1/best_chi_2) + 1
            inertia = inertia_bounds[0] + (ranks * (inertia_bounds[1]
                                    - inertia_bounds[0]))/ranks.shape[0]
            inertia = inertia.reshape(-1,1)
        else:
            print(&#34;Unknown inertia type!&#34;, inertia)
            print(&#34;Setting inertia to 0.5&#34;)
            inertia = 0.5
    if use_matrix:
        R1 = np.random.uniform(0,1,size=(position.shape[0],
                                        position.shape[1]))
        R2 = np.random.uniform(0,1,size=(position.shape[0],
                                        position.shape[1]))
    else:
        R1 = np.random.uniform(0,1,size=(position.shape[0], 1))
        R2 = np.random.uniform(0,1,size=(position.shape[0], 1))

    new_velocity = (inertia*previous_velocity
                    + c1*R1*(global_best_pos - position)
                    + c2*R2*(particle_best_pos - position))

    return new_velocity</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.get_CIF_of_best"><code class="name flex">
<span>def <span class="ident">get_CIF_of_best</span></span>(<span>self, n_reflections=None, one_for_each_subswarm=True, filename_root=None, run=None, start_time=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Get a CIF of the best results found by the particle swarm</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_reflections</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of reflections used in the
SDPD attempts. May be useful if comparing resolutions, but not
normally needed. If None, then n_reflections = all reflections.
Defaults to None.</dd>
<dt><strong><code>one_for_each_subswarm</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>A separate CIF for every
independent subswarm rather than just the best globally.
Defaults to True.</dd>
<dt><strong><code>filename_root</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Specify the root filename to use.
If None, then use the structure name as the root.
Defaults to None.</dd>
<dt><strong><code>run</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The GALLOP iteration. Defaults to None.</dd>
<dt><strong><code>start_time</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>A float produced by time.time() that
indicates when the run started. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_CIF_of_best(self, n_reflections=None, one_for_each_subswarm=True,
                            filename_root=None, run=None, start_time=None):
    &#34;&#34;&#34;
    Get a CIF of the best results found by the particle swarm

    Args:
        n_reflections (int, optional): The number of reflections used in the
            SDPD attempts. May be useful if comparing resolutions, but not
            normally needed. If None, then n_reflections = all reflections.
            Defaults to None.
        one_for_each_subswarm (bool, optional): A separate CIF for every
            independent subswarm rather than just the best globally.
            Defaults to True.
        filename_root (str, optional): Specify the root filename to use.
            If None, then use the structure name as the root.
            Defaults to None.
        run (int, optional): The GALLOP iteration. Defaults to None.
        start_time (float, optional): A float produced by time.time() that
            indicates when the run started. Defaults to None.
    &#34;&#34;&#34;
    if not one_for_each_subswarm:
        external, internal = self.get_new_external_internal(
                                                self.particle_best_position)
        chi_2 = self.best_chi_2
        external = external[chi_2 == chi_2.min()]
        internal = internal[chi_2 == chi_2.min()]
        if external.shape[0] &gt; 1:
            external = external[0]
            internal = internal[0]
        chi_2 = chi_2.min()
        external = external.reshape(1,-1)
        internal = internal.reshape(1,-1)
    else:
        positions, chi2s = [], []
        for i in range(self.n_swarms):
            subswarm = self.n_particles // self.n_swarms
            begin = i*subswarm
            end = (i+1)*subswarm
            swarm_best_pos = self.particle_best_position[begin:end]
            swarm_chi2 = self.best_chi_2[begin:end]
            best_pos = swarm_best_pos[swarm_chi2 == swarm_chi2.min()]
            # If more than one particle has the same chi2, only save one
            # of them.
            if best_pos.shape[0] &gt; 1:
                best_pos = best_pos[0].reshape(1,-1)
            best_chi_2 = swarm_chi2.min()
            positions.append(best_pos)
            chi2s.append(best_chi_2)
        positions = np.vstack(positions)
        chi2s = np.array(chi2s)
        external, internal = self.get_new_external_internal(positions)
    if filename_root is None:
        filename_root = self.Structure.name
    for i in range(external.shape[0]):
        result = {}
        result[&#34;external&#34;] = external[i]
        result[&#34;internal&#34;] = internal[i]
        result[&#34;chi_2&#34;] = chi2s[i]
        if run is None:
            result[&#34;GALLOP Iter&#34;] = len(self.swarm_progress)
        else:
            result[&#34;GALLOP Iter&#34;] = run
        if start_time is None:
            start_time = time.time()
        files.save_CIF_of_best_result(self.Structure, result, start_time,
                                n_reflections, filename_root=filename_root
                                +&#34;_swarm_&#34;+str(i))</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.get_initial_positions"><code class="name flex">
<span>def <span class="ident">get_initial_positions</span></span>(<span>self, method='latin', latin_criterion=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate the initial starting points for a GALLOP attempt. The
recommended method uses latin hypercube sampling which provides a
more even coverage of the search space than random uniform sampling,
which can produce clusters or leave regions unexplored.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>method</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The sampling method to use. Can be one of
"latin" or "uniform". Defaults to "latin".</dd>
<dt><strong><code>latin_criterion</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The criterion to be used with the
latin hypercube method. See pyDOE documentation here:
<a href="https://pythonhosted.org/pyDOE/randomized.html#latin-hypercube">https://pythonhosted.org/pyDOE/randomized.html#latin-hypercube</a>
Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Tuple of numpy arrays containing the initial external and</dd>
</dl>
<p>internal degrees of freedom</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_initial_positions(self, method=&#34;latin&#34;, latin_criterion=None):
    &#34;&#34;&#34;
    Generate the initial starting points for a GALLOP attempt. The
    recommended method uses latin hypercube sampling which provides a
    more even coverage of the search space than random uniform sampling,
    which can produce clusters or leave regions unexplored.

    Args:
        method (str, optional): The sampling method to use. Can be one of
            &#34;latin&#34; or &#34;uniform&#34;. Defaults to &#34;latin&#34;.
        latin_criterion (str, optional): The criterion to be used with the
            latin hypercube method. See pyDOE documentation here:
            https://pythonhosted.org/pyDOE/randomized.html#latin-hypercube
            Defaults to None.

    Returns:
        tuple: Tuple of numpy arrays containing the initial external and
        internal degrees of freedom
    &#34;&#34;&#34;
    if self.Structure.total_internal_degrees_of_freedom is None:
        self.Structure.get_total_degrees_of_freedom()

    assert method in [&#34;uniform&#34;, &#34;latin&#34;], &#34;method must be latin or uniform&#34;
    if self.n_particles % self.n_swarms != 0:
        print(&#34;n_particles should be divisible by n_swarms.&#34;)
        self.n_particles = self.n_swarms * (self.n_particles//self.n_swarms)
        print(&#34;Setting n_particles to&#34;, self.n_particles)
    subswarm = self.n_particles // self.n_swarms
    init_external = []
    init_internal = []

    total_pos = self.Structure.total_position_degrees_of_freedom
    total_rot = self.Structure.total_rotation_degrees_of_freedom
    tot_external = total_pos+total_rot
    total_tors = self.Structure.total_internal_degrees_of_freedom
    # Separate hypercube for each subswarm
    for _ in tqdm.tqdm(range(self.n_swarms)):
        if method == &#34;latin&#34;:
            all_dof = np.array(pyDOE.lhs(total_pos + total_rot + total_tors,
                        samples=subswarm, criterion=latin_criterion))
            external = all_dof[:,:total_pos+total_rot]
            pos = external[:,:total_pos]
            rot = external[:,total_pos:]
            tor = all_dof[:,total_pos+total_rot:]
            rot -= 0.5
            rot *= 2. # Rotation to range [-1,1]
            tor -= 0.5
            tor *= 2. * np.pi # Torsions to range [-pi,pi]
            init_external.append(np.hstack([pos,rot]))
            init_internal.append(tor)

        else:
            rand_ext = np.random.uniform(-1,1,size=(subswarm,tot_external))
            rand_int = np.random.uniform(-1,1,size=(subswarm,total_tors))
            init_external.append(rand_ext)
            init_internal.append(rand_int)

    init_external = np.vstack(init_external)
    init_internal = np.vstack(init_internal)
    return init_external, init_internal</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.get_new_external_internal"><code class="name flex">
<span>def <span class="ident">get_new_external_internal</span></span>(<span>self, position)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the swarm representation of position back to the external
and internal degrees of freedom expected by GALLOP</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>position</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>The internal swarm representation of the
particle positions, where the positions and torsion angles have
been projected onto the unit circle.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Tuple of numpy arrays containing the external and internal
degrees of freedom</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_new_external_internal(self, position):
    &#34;&#34;&#34;
    Convert the swarm representation of position back to the external
    and internal degrees of freedom expected by GALLOP

    Args:
        position (numpy array): The internal swarm representation of the
            particle positions, where the positions and torsion angles have
            been projected onto the unit circle.

    Returns:
        tuple: Tuple of numpy arrays containing the external and internal
            degrees of freedom
    &#34;&#34;&#34;
    total_position = self.Structure.total_position_degrees_of_freedom
    total_rotation = self.Structure.total_rotation_degrees_of_freedom
    total_torsional = self.Structure.total_internal_degrees_of_freedom
    n_quaternions = total_rotation // 4
    end_external = (2*total_position) + total_rotation
    external = np.copy(position[:,:end_external])
    internal = np.copy(position[:,end_external:])
    # Reverse the normalisation of the particle position,
    # back to range 0 - 1
    pos_sines = external[:,:total_position]
    pos_cosines = external[:,total_position:2*total_position]
    # Can now use the inverse tangent to get positions in range -0.5, 0.5
    translations = np.arctan2(pos_sines, pos_cosines) / (2*np.pi)

    rotations = external[:,2*total_position:]
    rotation_list = []
    for i in range(n_quaternions):
        # Ensure the quaternions are unit quaternions
        quaternion = rotations[:,(i*4):(i+1)*4]
        quaternion /= np.sqrt((quaternion**2).sum(axis=1)).reshape(-1,1)
        rotation_list.append(quaternion)
    rotations = np.hstack(rotation_list)

    external = np.hstack([translations, rotations])
    # Revert torsion representation back to angles using the inverse tangent
    internal = np.arctan2(internal[:,:total_torsional],
                        internal[:,total_torsional:])

    return external, internal</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.get_new_velocities"><code class="name flex">
<span>def <span class="ident">get_new_velocities</span></span>(<span>self, global_update=True, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the particle velocities using the PSO equations.
Can either update all particles as a single swarm, or treat them as a
set of independent swarms (or subswarms).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>global_update</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, update all of the particles
as a single swarm. If False, then update n_swarms separately.
Defaults to True.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print out if a global update is being
performed. Defaults to True.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_new_velocities(self, global_update=True, verbose=True):
    &#34;&#34;&#34;
    Update the particle velocities using the PSO equations.
    Can either update all particles as a single swarm, or treat them as a
    set of independent swarms (or subswarms).

    Args:
        global_update (bool, optional): If True, update all of the particles
            as a single swarm. If False, then update n_swarms separately.
            Defaults to True.
        verbose (bool, optional): Print out if a global update is being
            performed. Defaults to True.
    &#34;&#34;&#34;
    subswarm = self.n_particles // self.n_swarms
    use_ranked_all = False
    if isinstance(self.inertia, str):
        if self.inertia.lower() == &#34;ranked_all&#34;:
            ranks = np.argsort(self.best_chi_2) + 1
            ranked_inertia = (self.inertia_bounds[0]
                        + (ranks * (self.inertia_bounds[1]
                        - self.inertia_bounds[0]))/ranks.shape[0])
            ranked_inertia = ranked_inertia.reshape(-1,1)
            use_ranked_all = True
    if global_update:
        if verbose:
            print(&#34;Global&#34;)
        if use_ranked_all:
            self.velocity = self.PSO_velocity_update(self.velocity,
                                self.position, self.particle_best_position,
                                self.best_chi_2, inertia=ranked_inertia,
                                c1=self.c1, c2=self.c2,
                                inertia_bounds=self.inertia_bounds,
                                use_matrix=self.use_matrix)
        else:
            self.velocity = self.PSO_velocity_update(self.velocity,
                                self.position, self.particle_best_position,
                                self.best_chi_2, inertia=self.inertia,
                                c1=self.c1, c2=self.c2,
                                inertia_bounds=self.inertia_bounds,
                                use_matrix=self.use_matrix)
        for j in range(self.n_swarms):
            begin = j*subswarm
            end = (j+1)*subswarm
            self.best_subswarm_chi2.append(self.best_chi_2[begin:end].min())
        self.swarm_progress.append(self.best_subswarm_chi2)
    else:
        for j in range(self.n_swarms):
            begin = j*subswarm
            end = (j+1)*subswarm
            swarm_v = self.velocity[begin:end]
            swarm_pos = self.position[begin:end]
            swarm_best_pos = self.particle_best_position[begin:end]
            swarm_chi2 = self.best_chi_2[begin:end]
            if use_ranked_all:
                swarm_ranked_inertia = ranked_inertia[begin:end]
                new_vel = self.PSO_velocity_update(swarm_v, swarm_pos,
                        swarm_best_pos, swarm_chi2,
                        inertia=swarm_ranked_inertia,
                        c1=self.c1, c2=self.c2,
                        inertia_bounds=self.inertia_bounds,
                        use_matrix=self.use_matrix)
            else:
                new_vel = self.PSO_velocity_update(swarm_v, swarm_pos,
                        swarm_best_pos, swarm_chi2, inertia=self.inertia,
                        c1=self.c1, c2=self.c2,
                        inertia_bounds=self.inertia_bounds,
                        use_matrix=self.use_matrix)
            self.velocity[begin:end] = new_vel
            self.best_subswarm_chi2.append(swarm_chi2.min())
        self.swarm_progress.append(self.best_subswarm_chi2)

    if self.limit_velocity:
        unlimited = self.velocity
        self.velocity[unlimited &gt; self.vmax] = self.vmax
        self.velocity[unlimited &lt; -1*self.vmax] = -1*self.vmax</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.get_position_from_dof"><code class="name flex">
<span>def <span class="ident">get_position_from_dof</span></span>(<span>self, external, internal)</span>
</code></dt>
<dd>
<div class="desc"><p>Particle position values are unbounded, which can cause some issues
with the swarm updates. This can be remedied in part by normalising
all of the coordinates into the range -1 to +1.
It also means that all of the coordinates will have the same range in
the swarm, allowing easy comparison of exploration directions.</p>
<p>For torsions, this is simple - merely take sin and cosine of the angles.
For quaternions, ensuring that they are unit quaternions should do the
trick.
For the translations, this function uses the following:
2 * ((translation % 1) - 0.5)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Structure</code></strong> :&ensp;<code>class</code></dt>
<dd>GALLOP structure which holds information about
which indices of external and internal correspond to
translations and rotations</dd>
<dt><strong><code>external</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>External degrees of freedom</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>Internal degrees of freedom</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>numpy array </code></dt>
<dd>The normalised and stacked positions of the particles.
Order is translation, rotation, torsion</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_position_from_dof(self, external, internal):
    &#34;&#34;&#34;
    Particle position values are unbounded, which can cause some issues
    with the swarm updates. This can be remedied in part by normalising
    all of the coordinates into the range -1 to +1.
    It also means that all of the coordinates will have the same range in
    the swarm, allowing easy comparison of exploration directions.

    For torsions, this is simple - merely take sin and cosine of the angles.
    For quaternions, ensuring that they are unit quaternions should do the
    trick.
    For the translations, this function uses the following:
        2 * ((translation % 1) - 0.5)

    Args:
        Structure (class): GALLOP structure which holds information about
            which indices of external and internal correspond to
            translations and rotations
        external (numpy array): External degrees of freedom
        internal (numpy array): Internal degrees of freedom

    Returns:
        numpy array : The normalised and stacked positions of the particles.
            Order is translation, rotation, torsion
    &#34;&#34;&#34;
    end_of_translations = self.Structure.total_position_degrees_of_freedom
    n_quaternions = self.Structure.total_rotation_degrees_of_freedom // 4
    translation = np.copy(external[:,:end_of_translations])
    translation = translation % 1    # Convert into range(0,1)
    translation *= 2 * np.pi         # Convert into range(0, 2pi)
    translation = np.hstack([np.sin(translation), np.cos(translation)])

    rotation = np.copy(external[:,end_of_translations:])
    rotation_list = []
    for i in range(n_quaternions):
        # Ensure quaternions are unit quaternions
        quaternion = rotation[:,(i*4):(i+1)*4]
        quaternion /= np.sqrt((quaternion**2).sum(axis=1)).reshape(-1,1)
        rotation_list.append(quaternion)
    rotation = np.hstack(rotation_list)
    # Take the sin and cos of the torsions, and stack everything.
    # Range for all parameters is now -1 to +1
    position = np.hstack([translation, rotation,
                            np.sin(internal), np.cos(internal)])

    return position</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.reset_position_and_velocity"><code class="name flex">
<span>def <span class="ident">reset_position_and_velocity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Reset the Particle swarm</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_position_and_velocity(self):
    &#34;&#34;&#34;
    Reset the Particle swarm
    &#34;&#34;&#34;
    self.particle_best_position = None
    self.n_particles = None
    self.velocity = None</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.update_best"><code class="name flex">
<span>def <span class="ident">update_best</span></span>(<span>self, chi_2)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the swarm with the best position and chi_2 for each particle</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>chi_2</code></strong> :&ensp;<code>numpy array</code></dt>
<dd>the most recently obtained chi_2 values</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_best(self, chi_2):
    &#34;&#34;&#34;
    Update the swarm with the best position and chi_2 for each particle

    Args:
        chi_2 (numpy array): the most recently obtained chi_2 values
    &#34;&#34;&#34;
    better = chi_2 &lt; self.best_chi_2
    self.particle_best_position[better] = self.position[better]
    self.best_chi_2[better] = chi_2[better]</code></pre>
</details>
</dd>
<dt id="gallop.optimiser.Swarm.update_position"><code class="name flex">
<span>def <span class="ident">update_position</span></span>(<span>self, result=None, external=None, internal=None, chi_2=None, run=None, global_update=False, verbose=True, n_swarms=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Take a set of results from the minimisation algorithm and use
them to generate a new set of starting points to be minimised. This
will also update the internal swarm representation of position and
velocity.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>The result dict from a GALLOP minimise run.
Defaults to None.</dd>
<dt><strong><code>external</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>If no result dict is supplied,
then pass a numpy array of the external DoF. Defaults to None.</dd>
<dt><strong><code>internal</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>If no result dict is supplied,
then pass a numpy array of the internal DoF. Defaults to None.</dd>
<dt><strong><code>chi_2</code></strong> :&ensp;<code>numpy array</code>, optional</dt>
<dd>If no result dict is supplied,
then pass a numpy array of the chi_2 values. Defaults to None.</dd>
<dt><strong><code>run</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If no result dict is supplied, then pass the
run number. Defaults to None.</dd>
<dt><strong><code>global_update</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, update all of the particles
as a single swarm. Defaults to False.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print out information. Defaults to True.</dd>
<dt><strong><code>n_swarms</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>If global_update is False, it use the
Swarm.n_swarms parameter. This value can be overwritten if
desired by supplying it as an argument. This could be useful for
strategies that enable small subswarms to communicate, e.g.
initially have 2^n swarms, then after some iterations, change to
2^(n-1) swarms for 1 or more iterations. This would propagate
information between swarms without doing a full global update.
Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Tuple of numpy arrays containing the external and internal
degrees of freedom</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_position(self, result=None, external=None, internal=None,
    chi_2=None, run=None, global_update=False, verbose=True, n_swarms=None):
    &#34;&#34;&#34;
    Take a set of results from the minimisation algorithm and use
    them to generate a new set of starting points to be minimised. This
    will also update the internal swarm representation of position and
    velocity.

    Args:
        result (dict, optional): The result dict from a GALLOP minimise run.
            Defaults to None.
        external (numpy array, optional): If no result dict is supplied,
            then pass a numpy array of the external DoF. Defaults to None.
        internal (numpy array, optional): If no result dict is supplied,
            then pass a numpy array of the internal DoF. Defaults to None.
        chi_2 (numpy array, optional): If no result dict is supplied,
            then pass a numpy array of the chi_2 values. Defaults to None.
        run (int, optional): If no result dict is supplied, then pass the
            run number. Defaults to None.
        global_update (bool, optional): If True, update all of the particles
            as a single swarm. Defaults to False.
        verbose (bool, optional): Print out information. Defaults to True.
        n_swarms (int, optional): If global_update is False, it use the
            Swarm.n_swarms parameter. This value can be overwritten if
            desired by supplying it as an argument. This could be useful for
            strategies that enable small subswarms to communicate, e.g.
            initially have 2^n swarms, then after some iterations, change to
            2^(n-1) swarms for 1 or more iterations. This would propagate
            information between swarms without doing a full global update.
            Defaults to None.

    Returns:
        tuple: Tuple of numpy arrays containing the external and internal
            degrees of freedom
    &#34;&#34;&#34;
    if result is not None:
        external = result[&#34;external&#34;]
        internal = result[&#34;internal&#34;]
        chi_2 = result[&#34;chi_2&#34;]
        run = result[&#34;GALLOP Iter&#34;]
    else:
        if external is None and internal is None:
            print(&#34;No DoFs supplied!&#34;)
            exit()
    self.position = self.get_position_from_dof(external, internal)
    if self.n_particles is None:
        self.n_particles = external.shape[0]

    if n_swarms is not None:
        self.n_swarms = n_swarms

    if self.particle_best_position is None:
        self.particle_best_position = np.copy(self.position)
        self.best_chi_2 = np.copy(chi_2)
    if self.velocity is None:
        self.velocity = np.zeros_like(self.position)
    self.update_best(chi_2)

    if not global_update:
        if self.global_update_freq is not None and self.global_update:
            if (run+1) % self.global_update_freq == 0 and run != 0:
                global_update = True
    self.get_new_velocities(global_update=global_update, verbose=verbose)
    self.position = self.position + self.velocity

    if verbose:
        print(self.velocity.min(), self.velocity.max(),
        self.velocity.mean(),
        self.velocity.std(), np.abs(self.velocity).mean(),
        np.abs(self.velocity).std())

    external, internal = self.get_new_external_internal(self.position)

    return external, internal</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gallop" href="index.html">gallop</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="gallop.optimiser.adjust_lr_1_cycle" href="#gallop.optimiser.adjust_lr_1_cycle">adjust_lr_1_cycle</a></code></li>
<li><code><a title="gallop.optimiser.adjust_lr_1_over_sqrt" href="#gallop.optimiser.adjust_lr_1_over_sqrt">adjust_lr_1_over_sqrt</a></code></li>
<li><code><a title="gallop.optimiser.find_learning_rate" href="#gallop.optimiser.find_learning_rate">find_learning_rate</a></code></li>
<li><code><a title="gallop.optimiser.get_minimiser_settings" href="#gallop.optimiser.get_minimiser_settings">get_minimiser_settings</a></code></li>
<li><code><a title="gallop.optimiser.minimise" href="#gallop.optimiser.minimise">minimise</a></code></li>
<li><code><a title="gallop.optimiser.plot_torsion_difference" href="#gallop.optimiser.plot_torsion_difference">plot_torsion_difference</a></code></li>
<li><code><a title="gallop.optimiser.seed_everything" href="#gallop.optimiser.seed_everything">seed_everything</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="gallop.optimiser.Swarm" href="#gallop.optimiser.Swarm">Swarm</a></code></h4>
<ul class="">
<li><code><a title="gallop.optimiser.Swarm.PSO_velocity_update" href="#gallop.optimiser.Swarm.PSO_velocity_update">PSO_velocity_update</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.get_CIF_of_best" href="#gallop.optimiser.Swarm.get_CIF_of_best">get_CIF_of_best</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.get_initial_positions" href="#gallop.optimiser.Swarm.get_initial_positions">get_initial_positions</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.get_new_external_internal" href="#gallop.optimiser.Swarm.get_new_external_internal">get_new_external_internal</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.get_new_velocities" href="#gallop.optimiser.Swarm.get_new_velocities">get_new_velocities</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.get_position_from_dof" href="#gallop.optimiser.Swarm.get_position_from_dof">get_position_from_dof</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.reset_position_and_velocity" href="#gallop.optimiser.Swarm.reset_position_and_velocity">reset_position_and_velocity</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.update_best" href="#gallop.optimiser.Swarm.update_best">update_best</a></code></li>
<li><code><a title="gallop.optimiser.Swarm.update_position" href="#gallop.optimiser.Swarm.update_position">update_position</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>